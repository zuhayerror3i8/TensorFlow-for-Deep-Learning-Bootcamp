{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP30Ulz8sYf93320NkXVi1q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zuhayerror3i8/TensorFlow-for-Deep-Learning-Bootcamp/blob/main/Section%2007%20-%20Transfer%20Learning%20in%20TensorFlow%20Part%2002%20(Fine%20tuning)/05_transfer_learning_in_tensorflow_part_02_(fine_tuning).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transfer Learning with TensorFlow Part 02 (Fine tuning)\n",
        "\n",
        "In the previous notebook, we covered transfer learning feature extraction, now it's time to learn about a new kind of transfer learning: fine-tuning."
      ],
      "metadata": {
        "id": "i6hd_uW0SOI1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if we're using a GPU\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "ONE5LNnGS-TF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating helper functions\n",
        "\n",
        "In the previous notebooks, we've created a bunch of helper functions, now we could rewrite them all. However, this is tedious!\n",
        "\n",
        "So, it's a good idea to put functions you'll want to use again in a script you can download and import into your notebooks (or elsewhere).\n",
        "\n",
        "We've done this for some of the functions we've used previously here:\n",
        "https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/refs/heads/main/extras/helper_functions.py"
      ],
      "metadata": {
        "id": "_qedh6A6TIQw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/refs/heads/main/extras/helper_functions.py"
      ],
      "metadata": {
        "id": "K-E0KeY9TuN1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import helper functions we're going to use in this notebook\n",
        "from helper_functions import create_tensorboard_callback, plot_loss_curves, unzip_data, walk_through_dir"
      ],
      "metadata": {
        "id": "xkg8_fWsU1Uj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Note:** If you're running this notebook in Google Colab, when it times out, Colab will delete helper_functions.py. So, you'll have to redownload it, if you want to access to your helper functions."
      ],
      "metadata": {
        "id": "09KNr5u-VWYE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Let's get some data\n",
        "\n",
        "This time we're going to see how we can use the pre-trained models `tf.keras.applications` and apply them to our own problem (recognizing images of food).\n",
        "\n",
        "Link: https://www.tensorflow.org/api_docs/python/tf/keras/applications"
      ],
      "metadata": {
        "id": "kHgRy5cgbCAa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get 10% of training data of 10 classes of Food101\n",
        "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\n",
        "\n",
        "unzip_data(\"10_food_classes_10_percent.zip\")"
      ],
      "metadata": {
        "id": "vOw3qrNUbqnJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out how many images and subdirectories are in our dataset\n",
        "walk_through_dir(\"10_food_classes_10_percent\")"
      ],
      "metadata": {
        "id": "wWrjUCRacK_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create training and test directory paths\n",
        "train_dir = \"10_food_classes_10_percent/train/\"\n",
        "test_dir = \"10_food_classes_10_percent/test/\""
      ],
      "metadata": {
        "id": "Sp3RzxV9chRO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "IMG_SIZE = (224, 224)\n",
        "\n",
        "train_data_10_percent = tf.keras.preprocessing.image_dataset_from_directory(directory=train_dir,\n",
        "                                                                            image_size=IMG_SIZE,\n",
        "                                                                            label_mode=\"categorical\",\n",
        "                                                                            batch_size=32)\n",
        "\n",
        "test_data = tf.keras.preprocessing.image_dataset_from_directory(directory=test_dir,\n",
        "                                                                image_size=IMG_SIZE,\n",
        "                                                                label_mode=\"categorical\",\n",
        "                                                                batch_size=32)"
      ],
      "metadata": {
        "id": "Wb8CbGNOcqy_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out the class names of our dataset\n",
        "train_data_10_percent.class_names"
      ],
      "metadata": {
        "id": "Q-Nnz_BceNZF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# See an example of a batch of data\n",
        "for images, labels in train_data_10_percent.take(1):\n",
        "  print(images, labels)"
      ],
      "metadata": {
        "id": "zQqP7kwoeXLa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 0: Building a transfer learning feature extraction model using the Keras Functional API\n",
        "\n",
        "The sequential API is straight-forward, it runs our layers in sequential order.\n",
        "\n",
        "But the functional API gives us more flexibility with our models."
      ],
      "metadata": {
        "id": "ehDZ6lWKgl2i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Create the base model with tf.keras.applications\n",
        "base_model = tf.keras.applications.EfficientNetB0(include_top=False)\n",
        "\n",
        "# 2. Freeze the base model (so, the underlying pre-trained patterns aren't updated during training)\n",
        "base_model.trainable = False\n",
        "\n",
        "# 3. Create inputs into our model\n",
        "inputs = tf.keras.layers.Input(shape=(224, 224, 3), name=\"input_layer\")\n",
        "\n",
        "# 4. If using a model like ResNet50V2 you will need to normalize inputs (you don't have to for EfficientNet(s))\n",
        "# x = tf.keras.layers.experimental.preprocessing.Rescaling(1./255)(inputs)\n",
        "\n",
        "# 5. Pass the inputs to the base_model\n",
        "x = base_model(inputs)\n",
        "print(f\"Shape after passing inputs through base model: {x.shape}\")\n",
        "\n",
        "# 6. Average pool the outputs of the base model (aggregate all the most important informations, reduce the number of computations)\n",
        "x = tf.keras.layers.GlobalAveragePooling2D(name=\"global_average_pooling_layer\")(x)\n",
        "print(f\"Shape after GlobalAveragePooling2D: {x.shape}\")\n",
        "\n",
        "# 7. Create the output activation layer\n",
        "outputs = tf.keras.layers.Dense(10, activation=\"softmax\", name=\"output_layer\")(x)\n",
        "\n",
        "# 8. Combine the inputs with the outputs into a model\n",
        "model_0 = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "# 9. Compile the model\n",
        "model_0.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# 10. Fit the model and save its history\n",
        "history_10_percent = model_0.fit(train_data_10_percent,\n",
        "                                 epochs=5,\n",
        "                                 steps_per_epoch=len(train_data_10_percent),\n",
        "                                 validation_data=test_data,\n",
        "                                 validation_steps=int(0.25 * len(test_data)),\n",
        "                                 callbacks=[create_tensorboard_callback(\"transfer_learning\",\n",
        "                                                                        \"10_percent_feature_extraction\")])"
      ],
      "metadata": {
        "id": "uP-APOPvhEx3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate on the full test dataset\n",
        "model_0.evaluate(test_data)"
      ],
      "metadata": {
        "id": "zqoiFSfBvlxM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the layers in our base model\n",
        "for layer_number, layer in enumerate(base_model.layers):\n",
        "  print(layer_number, layer.name)"
      ],
      "metadata": {
        "id": "Bm7k_4m_vx7J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# How about we get the summary of the base model?\n",
        "base_model.summary()"
      ],
      "metadata": {
        "id": "PgEeQRkVwOGm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# How about the summary of our whole model?\n",
        "model_0.summary()"
      ],
      "metadata": {
        "id": "mcyaoFBVwiQ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out our model's training curves\n",
        "plot_loss_curves(history_10_percent)"
      ],
      "metadata": {
        "id": "32B91ZBzw16B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting a feature vector from a trained model\n",
        "\n",
        "Let's demostrate the Global Average Pooling 2D layer...\n",
        "\n",
        "We have a tensor after our model goes through `base_mode` of shape (None, 7, 7, 1280).\n",
        "\n",
        "But then when it passes through GlobalAveragePooling2D, it turns into (None, 1280).\n",
        "\n",
        "Let's use a similar shaped tensor of (1, 4, 4, 3) and then pass it to GlobalAveragePooling2D."
      ],
      "metadata": {
        "id": "r18x3YmExRvz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the input shape\n",
        "input_shape = (1, 4, 4, 3)\n",
        "\n",
        "# Create a random tensor\n",
        "tf.random.set_seed(42)\n",
        "input_tensor = tf.random.normal(input_shape)\n",
        "print(f\"Random input tensor:\\n {input_tensor}\\n\")\n",
        "\n",
        "# Pass the random tensor through a global average pooling 2D layer\n",
        "global_average_pooled_tensor = tf.keras.layers.GlobalAveragePooling2D()(input_tensor)\n",
        "print(f\"2D global average pooled random tensor:\\n {global_average_pooled_tensor}\\n\")\n",
        "\n",
        "# Check the shape of the different tensors\n",
        "print(f\"Shape of input tensor: {input_tensor.shape}\")\n",
        "print(f\"Shape of Global Average Pooled 2D tensor: {global_average_pooled_tensor.shape}\")"
      ],
      "metadata": {
        "id": "1OUbHEWSyi2K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's replicate the GlobalAveragePooling2D layer\n",
        "tf.reduce_mean(input_tensor, axis=[1, 2])"
      ],
      "metadata": {
        "id": "GyiyY-A61RNu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:** One of the reasons feature extraction transfer learning is named how it is because what often happens is pre-trained model outputs a feature vector."
      ],
      "metadata": {
        "id": "SgzLcTxm2-kG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Running a series of transfer learning experiments\n",
        "\n",
        "We've seen the incredible results transfer learning can get with only 10% of the training data, but how does it go with 1% of the training data... How about we setup a bunch of experiments to find out:\n",
        "\n",
        "1. `model_1` - use feature extraction transfer learning with 1% of the training data with data augmentation.\n",
        "2. `model_2` - use feature extraction transfer learning with 10% of the training data with data augmentation.\n",
        "3. `model_3` - use fine-tuning transfer learning on 10% of the training data with data augmentation.\n",
        "4. `model_4` - use fine-tuning transfer learning on 100% of the training data with data augmentation.\n",
        "\n",
        "> **Note:** Throughout all experiments the same test dataset will be used to evaluate our model... This ensures consistency across evaluation metrics."
      ],
      "metadata": {
        "id": "xaqIL3cm39q2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Getting and preprocessing data for model_1"
      ],
      "metadata": {
        "id": "C1-KdXzqByYw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download and unzip data - preprocessed from Food101\n",
        "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_1_percent.zip\n",
        "\n",
        "unzip_data(\"10_food_classes_1_percent.zip\")"
      ],
      "metadata": {
        "id": "h4Mc6TDMAvdD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create training and test dirs\n",
        "train_dir_1_percent = \"10_food_classes_1_percent/train/\"\n",
        "test_dir_1_percent = \"10_food_classes_1_percent/test/\""
      ],
      "metadata": {
        "id": "7ZhzbuzJBBDA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# How many images are we working with?\n",
        "walk_through_dir(\"10_food_classes_1_percent\")"
      ],
      "metadata": {
        "id": "ORA8wAUFBOH1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup data loaders\n",
        "IMG_SIZE = (224, 224)\n",
        "\n",
        "train_data_1_percent = tf.keras.preprocessing.image_dataset_from_directory(train_dir_1_percent,\n",
        "                                                                           label_mode=\"categorical\",\n",
        "                                                                           image_size=IMG_SIZE,\n",
        "                                                                           batch_size=32)\n",
        "\n",
        "test_data = tf.keras.preprocessing.image_dataset_from_directory(test_dir_1_percent,\n",
        "                                                                label_mode=\"categorical\",\n",
        "                                                                image_size=IMG_SIZE,\n",
        "                                                                batch_size=32)"
      ],
      "metadata": {
        "id": "bGPF-mQ-BXW9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adding data augmentation right into the model\n",
        "\n",
        "To add data augmentation right into our models, we can use the layers inside:\n",
        "\n",
        "* tf.keras.layers()\n",
        "\n",
        "Off the top our of heads, after reading the docs, the benefits of using data augmentation inside the model are:\n",
        "\n",
        "* Preprocessing of images (augmenting them) happens on the GPU (much faster) rather than the CPU.\n",
        "* Image data augmentation only happens during training... So, we can still export our whole model and use it elsewhere."
      ],
      "metadata": {
        "id": "KaJeXP_uCoJi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Create data augmentation stage with horizontal flipping, rotations, zooms, etc.\n",
        "data_augmentation = keras.Sequential([\n",
        "    # preprocessing.Rescale(1./255), # Keep this for models like ResNet50V2\n",
        "    layers.RandomFlip(\"horizontal\"),\n",
        "    layers.RandomRotation(0.2),\n",
        "    layers.RandomZoom(0.2),\n",
        "    layers.RandomHeight(0.2),\n",
        "    layers.RandomWidth(0.2)\n",
        "], name=\"data_augmentation\")"
      ],
      "metadata": {
        "id": "WeZ-pp1gDX8Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualize our data augmentation layer (and see what happens to our data)"
      ],
      "metadata": {
        "id": "-Jp2zFThKU7d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# View a random image and compare it to its augmented version\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import os\n",
        "import random\n",
        "\n",
        "target_class = random.choice(train_data_1_percent.class_names)\n",
        "target_dir = \"10_food_classes_1_percent/train/\" + target_class\n",
        "random_image = random.choice(os.listdir(target_dir))\n",
        "random_image_path = target_dir + \"/\" + random_image\n",
        "\n",
        "# Read and plot in the random image\n",
        "img = mpimg.imread(random_image_path)\n",
        "plt.imshow(img)\n",
        "plt.title(f\"Original random image from class: {target_class}\")\n",
        "plt.axis(False)\n",
        "\n",
        "# Now let's plot our augmented random image\n",
        "augmented_img = data_augmentation(img, training=True)\n",
        "plt.figure()\n",
        "plt.imshow(augmented_img/255.)\n",
        "plt.title(f\"Augmented random image from class: {target_class}\")\n",
        "plt.axis(False)"
      ],
      "metadata": {
        "id": "HhFepsNgKdV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 1: Feature extraction transfer learning on 1% of the data with data augmentation"
      ],
      "metadata": {
        "id": "K9V9z-UXVqfL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# REINITIALIZATION\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Create data augmentation stage with horizontal flipping, rotations, zooms, etc.\n",
        "data_augmentation = keras.Sequential([\n",
        "    # layers.Rescale(1./255), # Keep this for models like ResNet50V2\n",
        "    layers.RandomFlip(\"horizontal\"),\n",
        "    layers.RandomRotation(0.2),\n",
        "    layers.RandomZoom(0.2),\n",
        "    layers.RandomHeight(0.2),\n",
        "    layers.RandomWidth(0.2)\n",
        "], name=\"data_augmentation\")"
      ],
      "metadata": {
        "id": "KkFga2a0fbLW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup input shape and base model, freezing the base model layers\n",
        "input_shape = (224, 224, 3)\n",
        "base_model = tf.keras.applications.EfficientNetB0(include_top=False)\n",
        "base_model.trainable = False\n",
        "\n",
        "# Create input layer\n",
        "inputs = layers.Input(shape=input_shape, name=\"input_layer\")\n",
        "\n",
        "# Add in data augmentation Sequential model as a layer\n",
        "x = data_augmentation(inputs)\n",
        "\n",
        "# Give base_model the inputs (after augmentation) and don't train it\n",
        "x = base_model(x, training=False)\n",
        "\n",
        "# Pool output features of the base model\n",
        "x = layers.GlobalAveragePooling2D()(x)\n",
        "\n",
        "# Put a dense layer on as the output\n",
        "outputs = layers.Dense(10, activation=\"softmax\", name=\"output_layer\")(x)\n",
        "\n",
        "# Make a model using the inputs and outputs\n",
        "model_1 = keras.Model(inputs, outputs)\n",
        "\n",
        "# Compile the model\n",
        "model_1.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# Fit the model\n",
        "history_1_percent = model_1.fit(train_data_1_percent,\n",
        "                                epochs=5,\n",
        "                                steps_per_epoch=len(train_data_1_percent),\n",
        "                                validation_data=test_data,\n",
        "                                validation_steps=int(0.25 * len(test_data)),\n",
        "                                callbacks=[create_tensorboard_callback(\"transfer_learning\",\n",
        "                                                                       \"1_percent_data_aug\")])"
      ],
      "metadata": {
        "id": "D670KewyWB-J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out the model summary\n",
        "model_1.summary()"
      ],
      "metadata": {
        "id": "6upINr37fzJK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate on the full test dataset\n",
        "model_1.evaluate(test_data)"
      ],
      "metadata": {
        "id": "u0sg3QrUf--e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# How do the model with 1% of the data and data augmentation loss curves look?\n",
        "plot_loss_curves(history_1_percent)"
      ],
      "metadata": {
        "id": "TtsqJ_glgogD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 2: feature extraction transfer learning model with 10% of data and data augmentation"
      ],
      "metadata": {
        "id": "zPN14b7YiHar"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get 10% of training data of 10 classes of Food101\n",
        "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\n",
        "\n",
        "unzip_data(\"10_food_classes_10_percent.zip\")"
      ],
      "metadata": {
        "id": "WW4ezELQn9zJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir_10_percent = \"10_food_classes_10_percent/train/\"\n",
        "test_dir_10_percent = \"10_food_classes_10_percent/test/\""
      ],
      "metadata": {
        "id": "XwXiBx-EoPDU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out how many images and subdirectories are in our dataset\n",
        "walk_through_dir(\"10_food_classes_10_percent\")"
      ],
      "metadata": {
        "id": "O_LKzecVpRfr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set data inputs\n",
        "import tensorflow as tf\n",
        "\n",
        "IMG_SIZE = (224, 224)\n",
        "\n",
        "train_data_10_percent = tf.keras.preprocessing.image_dataset_from_directory(train_dir_10_percent,\n",
        "                                                                            label_mode=\"categorical\",\n",
        "                                                                            image_size=IMG_SIZE)\n",
        "\n",
        "test_data = tf.keras.preprocessing.image_dataset_from_directory(test_dir_10_percent,\n",
        "                                                                label_mode=\"categorical\",\n",
        "                                                                image_size=IMG_SIZE)"
      ],
      "metadata": {
        "id": "fWaEGx6OoboI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create model_2 with data augmentation built in\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "# Build data augmentation layer\n",
        "data_augmentation = Sequential([\n",
        "    # layers.Rescale(1./255), # Keep this for models like ResNet50V2\n",
        "    layers.RandomFlip(\"horizintal\"),\n",
        "    layers.RandomHeight(0.2),\n",
        "    layers.RandomWidth(0.2),\n",
        "    layers.RandomZoom(0.2),\n",
        "    layers.RandomRotation(0.2)\n",
        "], name=\"data_augmentation\")\n",
        "\n",
        "# Setup the input shape to our model\n",
        "input_shape = (224, 224, 3)\n",
        "\n",
        "# Create a frozen base model (also called the backbone)\n",
        "base_model = tf.keras.applications.EfficientNetB0(include_top=False)\n",
        "base_model.trainable = False\n",
        "\n",
        "# Create the inputs and outputs (including the layers in between)\n",
        "inputs = layers.Input(shape=input_shape, name=\"input_layer\")\n",
        "x = data_augmentation(inputs) # Augment our training images (augmentation doesn't occur on test data)\n",
        "x = base_model(x, training=False) # Pass augmented images to base model but keep it in inference mode, this also ensures batchnorm layers don't get updated\n",
        "x = layers.GlobalAveragePooling2D(name=\"global_average_pooling_2D\")(x)\n",
        "outputs = layers.Dense(10, activation=\"softmax\", name=\"output_layer\")(x)\n",
        "model_2 = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "# Compile the model\n",
        "model_2.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "jqNyuKqvpTAT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating a ModelCheckpoint callback\n",
        "\n",
        "The ModelCheckpoint callback intermediately saves our model (the full model or just the weights) during training. This is useful... So, we can come and start where we left off."
      ],
      "metadata": {
        "id": "Xe6WxfJStI1y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set checkpoint path\n",
        "checkpoint_path = \"ten_percent_model_checkpoints_weights/checkpoint.weights.h5\"\n",
        "\n",
        "# Create a ModelCheckpoint callback that saves the model's weights only\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                                         save_weights_only=True,\n",
        "                                                         save_best_only=False,\n",
        "                                                         save_freq=\"epoch\",\n",
        "                                                         verbose=1)"
      ],
      "metadata": {
        "id": "Cdb1Wak4uJok"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fit model_2 passing in the ModelCheckpoint callback"
      ],
      "metadata": {
        "id": "UJejUv3hvT54"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model saving checkpoints every epoch\n",
        "initial_epochs = 5\n",
        "history_10_percent_data_aug = model_2.fit(train_data_10_percent,\n",
        "                                          epochs=initial_epochs,\n",
        "                                          steps_per_epoch=len(train_data_10_percent),\n",
        "                                          validation_data=test_data,\n",
        "                                          validation_steps=int(0.25 * len(test_data)),\n",
        "                                          callbacks=[create_tensorboard_callback(\"transfer_learning\",\n",
        "                                                                                 \"10_percent_data_aug\"),\n",
        "                                                     checkpoint_callback])"
      ],
      "metadata": {
        "id": "H0Rw3OtGvKXt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_10_percent_data_aug = model_2.evaluate(test_data)"
      ],
      "metadata": {
        "id": "xRDRxP3qy_J5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot model loss curves\n",
        "plot_loss_curves(history_10_percent_data_aug)"
      ],
      "metadata": {
        "id": "ft4Hh6TzzETf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading in checkpointed weights\n",
        "\n",
        "Loading in checkpointed weights return a model to a specific checkpoint."
      ],
      "metadata": {
        "id": "2l-xxbjnzfqX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load in saved model weights and evaluate model\n",
        "model_2.load_weights(checkpoint_path)"
      ],
      "metadata": {
        "id": "nvVqZhNOz9XJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate model_2 with loaded weights\n",
        "loaded_weights_model_results = model_2.evaluate(test_data)"
      ],
      "metadata": {
        "id": "TpxPHPd-0uC4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# If the results from our previously evaluated model_2 match the loaded weights, everything worked fine!\n",
        "results_10_percent_data_aug ==  loaded_weights_model_results"
      ],
      "metadata": {
        "id": "uDbItSt01VGt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_10_percent_data_aug"
      ],
      "metadata": {
        "id": "GksF26AK1kM0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_weights_model_results"
      ],
      "metadata": {
        "id": "N8KupuGn1mTW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check to see if loaded model results are very close to our previous non-loaded model results\n",
        "import numpy as np\n",
        "np.isclose(np.array(results_10_percent_data_aug),\n",
        "           np.array(loaded_weights_model_results))"
      ],
      "metadata": {
        "id": "tv2HF1QY1nRJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the difference between the two results\n",
        "print(np.array(results_10_percent_data_aug) - np.array(loaded_weights_model_results))"
      ],
      "metadata": {
        "id": "eytRZKCr2VG2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 3: Fine-tuning an existing model on 10% of the data\n",
        "\n",
        "> **Note:** Fine-tuning usually works best *after* training a feature extraction model for a few epochs with large amounts of custom data."
      ],
      "metadata": {
        "id": "jqpFRdpe3dLM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Layers in loaded model\n",
        "model_2.layers"
      ],
      "metadata": {
        "id": "2Qfd6mr8434H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Are these layers trainable?\n",
        "for layer in model_2.layers:\n",
        "  print(layer.name, layer.trainable)"
      ],
      "metadata": {
        "id": "WE6RSwl95FCl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# What layers are in our base_model (EfficientNetB0) and are they trainable?\n",
        "for i, layer in enumerate(model_2.layers[2].layers):\n",
        "  print(i, layer.name, layer.trainable)"
      ],
      "metadata": {
        "id": "qpvvD5fD5-wP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# How many trinable variables are in our base model?\n",
        "print(len(model_2.layers[2].trainable_variables))"
      ],
      "metadata": {
        "id": "fenEsVU56hie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To begin fine-tuning, let's start by setting the last 10 layers of our base_model.trainable = True\n",
        "base_model.trainable = True\n",
        "\n",
        "# Freeze all layers except for the last 10\n",
        "for layer in base_model.layers[:-10]:\n",
        "  layer.trainable = False\n",
        "\n",
        "# Recompile (we have to recompile our models every time we make a change)\n",
        "model_2.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), # When fine-tuning you typically want to lower the learning rate by 10x*\n",
        "                metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "_gRHm8V169XI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Note:** When using fine-tuning it's best practice to lower your learning rate by some amount. How much? This is a hyperparameter you can tune. But a good rule of thumb is at least 10x (though different sources will claim other values)."
      ],
      "metadata": {
        "id": "yTlL_vzl9jV6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check which layers are tunable (trainable)\n",
        "for layer_number, layer in enumerate(model_2.layers[2].layers):\n",
        "  print(layer_number, layer.name, layer.trainable)"
      ],
      "metadata": {
        "id": "itHLt-ge8TGS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now we've unfrozen some of the layers closer to the top, how many trainable parameters are there?\n",
        "print(len(model_2.trainable_variables))"
      ],
      "metadata": {
        "id": "3QqZ19A1_D0o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fine-tune for another 5 epochs\n",
        "fine_tune_epochs = initial_epochs + 5\n",
        "\n",
        "# Refit the model (same as model_2 except with more trainable layers)\n",
        "history_fine_10_percent_data_aug = model_2.fit(train_data_10_percent,\n",
        "                                               epochs=fine_tune_epochs,\n",
        "                                               steps_per_epoch=len(train_data_10_percent),\n",
        "                                               validation_data=test_data,\n",
        "                                               validation_steps=int(0.25 * len(test_data)),\n",
        "                                               initial_epoch=history_10_percent_data_aug.epoch[-1], # Start training from previous last epoch\n",
        "                                               callbacks=[create_tensorboard_callback(\"transfer_learning\",\n",
        "                                                                                      \"10_percent_fine_tune_last_10\")])"
      ],
      "metadata": {
        "id": "5OGtk1IN_kUC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the fine-tuned model (model_3 which is actually model_2 fine-tuned for another 5 epochs)\n",
        "results_fine_tune_10_percent = model_2.evaluate(test_data)"
      ],
      "metadata": {
        "id": "ebc7ZPCeKjGn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out the loss curves of our fine-tuned model\n",
        "plot_loss_curves(history_fine_10_percent_data_aug)"
      ],
      "metadata": {
        "id": "4zyez067LDi8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `plot_loss_curves` function works great with models which have only been fit once. However, we want something to compare one series of running `fit()` with another (e.g. before and after fine-tuning)."
      ],
      "metadata": {
        "id": "b4N77oZ4Lo9S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's create a function to compare training histories\n",
        "def compare_historys(original_history, new_history, initial_epochs=5):\n",
        "  \"\"\"\n",
        "  Compare two TensorFlow History objects.\n",
        "  \"\"\"\n",
        "\n",
        "  # Get original history measurements\n",
        "  acc = original_history.history[\"accuracy\"]\n",
        "  loss = original_history.history[\"loss\"]\n",
        "  val_acc = original_history.history[\"val_accuracy\"]\n",
        "  val_loss = original_history.history[\"val_loss\"]\n",
        "\n",
        "  # Combine original history\n",
        "  total_acc = acc + new_history.history[\"accuracy\"]\n",
        "  total_loss = loss + new_history.history[\"loss\"]\n",
        "  total_val_acc = val_acc + new_history.history[\"val_accuracy\"]\n",
        "  total_val_loss = val_loss + new_history.history[\"val_loss\"]\n",
        "\n",
        "  # Make plot for loss\n",
        "  plt.figure(figsize=(8, 8))\n",
        "  plt.subplot(2, 1, 2)\n",
        "  plt.plot(total_loss, label=\"Training Loss\")\n",
        "  plt.plot(total_val_loss, label=\"Val Loss\")\n",
        "  plt.plot([initial_epochs-1, initial_epochs-1], plt.ylim(), label=\"Start Fine Tuning\")\n",
        "  plt.legend(loc=\"upper right\")\n",
        "  plt.title(\"Training and Validation Loss\")\n",
        "\n",
        "  # Make plot for accuracy\n",
        "  plt.figure(figsize=(8, 8))\n",
        "  plt.subplot(2, 1, 1)\n",
        "  plt.plot(total_acc, label=\"Training Accuracy\")\n",
        "  plt.plot(total_val_acc, label=\"Val Accuracy\")\n",
        "  plt.plot([initial_epochs-1, initial_epochs-1], plt.ylim(), label=\"Start Fine Tuning\")\n",
        "  plt.legend(loc=\"lower right\")\n",
        "  plt.title(\"Training and Validation Accuracy\")"
      ],
      "metadata": {
        "id": "BTlcZtq-LldF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compare_historys(history_10_percent_data_aug,\n",
        "                 history_fine_10_percent_data_aug,\n",
        "                 initial_epochs=5)"
      ],
      "metadata": {
        "id": "aAXbRkrZOP9u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 4: Fine-tuning an existing model on all of the data"
      ],
      "metadata": {
        "id": "ZMB3yMFBO6Bf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download and unzip 10 classes of Food101 data with all images\n",
        "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_all_data.zip\n",
        "\n",
        "unzip_data(\"10_food_classes_all_data.zip\")"
      ],
      "metadata": {
        "id": "lcoBXaBvQUFA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup training and test dir\n",
        "train_dir_all_data = \"10_food_classes_all_data/train/\"\n",
        "test_dir = \"10_food_classes_all_data/test/\""
      ],
      "metadata": {
        "id": "9oLgEcu6QY_V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# How many images are we working with now?\n",
        "walk_through_dir(\"10_food_classes_all_data\")"
      ],
      "metadata": {
        "id": "Z_9nysFpQuRZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup data inputs\n",
        "import tensorflow as tf\n",
        "\n",
        "IMG_SIZE = (224, 224)\n",
        "\n",
        "train_data_10_classes_all = tf.keras.preprocessing.image_dataset_from_directory(train_dir_all_data,\n",
        "                                                                                label_mode=\"categorical\",\n",
        "                                                                                image_size=IMG_SIZE)\n",
        "\n",
        "test_data = tf.keras.preprocessing.image_dataset_from_directory(test_dir,\n",
        "                                                                label_mode=\"categorical\",\n",
        "                                                                image_size=IMG_SIZE)"
      ],
      "metadata": {
        "id": "Rt9DCuNJQ9bU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The test dataset we've loaded in is the same as what we've been using for previous experiments (all expreriments have used the same test dataset).\n",
        "\n",
        "Let's verify this..."
      ],
      "metadata": {
        "id": "UXhWCV6QSHt4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate model_2 (this is fine-tuned on 10 percent of data version)\n",
        "model_2.evaluate(test_data)"
      ],
      "metadata": {
        "id": "3kmH7SFeSqYT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_fine_tune_10_percent"
      ],
      "metadata": {
        "id": "IMXmSEgHS9L3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To train a fine-tuning model (model_4) we need to revert model_2 back to its feature extraction weights."
      ],
      "metadata": {
        "id": "My2ZgsdvTHGk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load weights from checkpoint, that way we can fine-tune from the same stage the 10 pecent data model was fine-tuned from\n",
        "model_2.load_weights(checkpoint_path)"
      ],
      "metadata": {
        "id": "pIaSi9jATXVn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's evaluate model_2 now\n",
        "model_2.evaluate(test_data)"
      ],
      "metadata": {
        "id": "AuCYlqwaUUBE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check to see if our model_2 has been reverted back to feature extraction results\n",
        "results_10_percent_data_aug"
      ],
      "metadata": {
        "id": "aqCV43SNVPXd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check which layers are tunable in the whole model\n",
        "for layer_number, layer in enumerate(model_2.layers):\n",
        "  print(layer_number, layer.name, layer.trainable)"
      ],
      "metadata": {
        "id": "94D0E1PGV4fG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's drill into our base_model (EfficientNetB0) and see what layers are trainable\n",
        "for layer_number, layer in enumerate(model_2.layers[2].layers):\n",
        "  print(layer_number, layer.name, layer.trainable)"
      ],
      "metadata": {
        "id": "B9Vx5R97WUYg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model_2.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "GS5aqKnSXNQS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Continue to train and fine-tune the model to our data (100% of training data)\n",
        "fine_tune_epochs = initial_epochs + 5\n",
        "\n",
        "history_fine_10_classes_all = model_2.fit(train_data_10_classes_all,\n",
        "                                          epochs=fine_tune_epochs,\n",
        "                                          steps_per_epoch=len(train_data_10_classes_all),\n",
        "                                          validation_data=test_data,\n",
        "                                          validation_steps=int(0.25 * len(test_data)),\n",
        "                                          initial_epoch=history_10_percent_data_aug.epoch[-1],\n",
        "                                          callbacks=[create_tensorboard_callback(\"transfer_learning\",\n",
        "                                                                                 \"all_10_classes_fine_tune_last_10\")])"
      ],
      "metadata": {
        "id": "0FRZQt9IX4-Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's evaluate on all of the test data\n",
        "results_fine_tune_all_data = model_2.evaluate(test_data)\n",
        "results_fine_tune_all_data"
      ],
      "metadata": {
        "id": "NuaTU9kkc2UY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# How did fine-tuning go with more data?\n",
        "compare_historys(original_history=history_10_percent_data_aug,\n",
        "                 new_history=history_fine_10_classes_all,\n",
        "                 initial_epochs=5)"
      ],
      "metadata": {
        "id": "myiuLRbodMhI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Viewing our experiment data on TensorBoard"
      ],
      "metadata": {
        "id": "B2mjaOktekq8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# View tensorboard logs of transfer learning modelling experiments (should be 4 models)\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir ./transfer_learning/"
      ],
      "metadata": {
        "id": "RTa-10cIe49W"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}