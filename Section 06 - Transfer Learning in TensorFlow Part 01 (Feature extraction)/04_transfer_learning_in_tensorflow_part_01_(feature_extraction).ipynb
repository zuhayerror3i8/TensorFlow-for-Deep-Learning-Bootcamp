{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPd74BPjSpISDEYA1XFunNb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zuhayerror3i8/TensorFlow-for-Deep-Learning-Bootcamp/blob/main/Section%2006%20-%20Transfer%20Learning%20in%20TensorFlow%20Part%2001%20(Feature%20extraction)/04_transfer_learning_in_tensorflow_part_01_(feature_extraction).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transfer learning with TensorFlow Part 01 (Feature Extraction)\n",
        "\n",
        "Transfer learning is leveraging a working model's existing architecture and learned pattern for our own problem.\n",
        "\n",
        "There are two main benefits:\n",
        "\n",
        "1. Can leverage an existing neural network architecture proven to work on problems similar to our own.\n",
        "2. Can leverage a working neural network architecture which has already learned patterns on similar data to our own, then we can adapt those patterns to our own data."
      ],
      "metadata": {
        "id": "caIzWmk7Xh2V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Are we using a GPU?\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "gCbyLk4X0Yvw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Downloading and becoming one with the data"
      ],
      "metadata": {
        "id": "zg5Bp2ZB0hcH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get data (10% of 10 food classes from Food101)\n",
        "import zipfile\n",
        "\n",
        "# Download the data\n",
        "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\n",
        "\n",
        "# Unzip the downloaded file\n",
        "zip_ref = zipfile.ZipFile(\"10_food_classes_10_percent.zip\")\n",
        "zip_ref.extractall()\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "sNUzFFiH0rZ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# How many images in each folder?\n",
        "import os\n",
        "\n",
        "# Walk through 10 percent data directory and list number of files\n",
        "for dirpath, dirnames, filenames, in os.walk(\"10_food_classes_10_percent\"):\n",
        "  print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")"
      ],
      "metadata": {
        "id": "Mzl1-nV61Ww8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create data loaders (preparing the data)\n",
        "\n",
        "We'll use the `ImageDataGenerator` class to load in our images in batches."
      ],
      "metadata": {
        "id": "AaVoUVZy2ND_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup data inputs\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "IMG_SHAPE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_dir = \"10_food_classes_10_percent/train/\"\n",
        "test_dir = \"10_food_classes_10_percent/test/\"\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "print(\"Training images:\")\n",
        "train_data_10_percent = train_datagen.flow_from_directory(train_dir,\n",
        "                                                          target_size=IMG_SHAPE,\n",
        "                                                          batch_size=BATCH_SIZE,\n",
        "                                                          class_mode=\"categorical\")\n",
        "\n",
        "print(\"Testing images:\")\n",
        "test_data = test_datagen.flow_from_directory(test_dir,\n",
        "                                             target_size=IMG_SHAPE,\n",
        "                                             batch_size=BATCH_SIZE,\n",
        "                                             class_mode=\"categorical\")"
      ],
      "metadata": {
        "id": "CKZNQp3x2bFq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting up callbacks (things to run whilst our model trains)\n",
        "\n",
        "callbacks are extra functionality you can add to your models to be performed during or after training. Some of the most popular callbacks:\n",
        "\n",
        "* Tracking experiments with the TensorBoard callback.\n",
        "* Model checkpoint with the ModelCheckPoint callback.\n",
        "* Stopping a model from training (before it trains too long and overfits) with the EarlyStopping callback."
      ],
      "metadata": {
        "id": "fzthz5v_4E0e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import tensorflow and tf_keras\n",
        "import tensorflow as tf\n",
        "import tf_keras as tfk"
      ],
      "metadata": {
        "id": "7oDl-qGT7BXN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create TensorBoard callback (functionality because we need to create a new one for each model)\n",
        "import datetime\n",
        "\n",
        "def create_tensorboard_callback(dir_name, experiment_name):\n",
        "  log_dir = dir_name + \"/\" + experiment_name + \"/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "  tensorboard_callback = tfk.callbacks.TensorBoard(log_dir=log_dir)\n",
        "  print(f\"Saving TensorBoard log files to: {log_dir}\")\n",
        "  return tensorboard_callback"
      ],
      "metadata": {
        "id": "-PGRtv3B5eLV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating models using TensorFlow\n",
        "\n",
        "In the past we've used TensorFlow to create our own models layer by layer form scratch.\n",
        "\n",
        "Now we're going to do a similar process, except the majority or our model's layers are going to come from TensorFlow Hub.\n",
        "\n",
        "We can access pretrained models on: https://www.kaggle.com/models\n",
        "\n",
        "Browsing the Kaggle Models page & sorting for image classification, we found the following feature vector model link: https://www.kaggle.com/models/tensorflow/efficientnet/TensorFlow2/b0-feature-vector/1"
      ],
      "metadata": {
        "id": "HN7YClJl7PA8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's compare the following two models\n",
        "resnet_url = \"https://www.kaggle.com/models/google/resnet-v2/TensorFlow2/50-feature-vector/2\"\n",
        "\n",
        "efficientnet_url = \"https://www.kaggle.com/models/tensorflow/efficientnet/TensorFlow2/b0-feature-vector/1\""
      ],
      "metadata": {
        "id": "Lh1F8ypa_veg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import dependencies\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub"
      ],
      "metadata": {
        "id": "dB6s5vXv_7mK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's make a create_model() function to create a model from a URL\n",
        "def create_model(model_url, num_classes=10):\n",
        "  \"\"\"\n",
        "  Takes a TensorFlow Hub URL and creates a Keras Sequential model with it.\n",
        "\n",
        "  Args:\n",
        "    model_url (str): A TensorFlow Hub feature extraction URL.\n",
        "    num_classes (int): Number of output neurons in the output layer, should be equal to number of target_classes, default 10.\n",
        "\n",
        "  Returns:\n",
        "    An uncompiled Keras Sequential model with model_url as feature extractor layer and Dense output layer with num_classes output neurons.\n",
        "  \"\"\"\n",
        "\n",
        "  # Download the pretrained model and save it as Keras Layer\n",
        "  feature_extraction_layer = hub.KerasLayer(model_url,\n",
        "                                            trainable=False,\n",
        "                                            name=\"feature_extraction_layer\",\n",
        "                                            input_shape=IMG_SHAPE+(3,)) # Freeze the already learned patterns\n",
        "\n",
        "  # Create our own model\n",
        "  model = tfk.Sequential([\n",
        "      feature_extraction_layer,\n",
        "      tfk.layers.Dense(num_classes, activation=\"softmax\", name=\"output_layer\")\n",
        "  ])\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "ss1mhEKFBHSy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating and testing ResNet TensorFlow Hub Feature Extraction model"
      ],
      "metadata": {
        "id": "SAjBYdQsD6Mz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Resnet model\n",
        "resnet_model = create_model(resnet_url,\n",
        "                            num_classes=train_data_10_percent.num_classes)"
      ],
      "metadata": {
        "id": "7br9O0zsDu_C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_model.summary()"
      ],
      "metadata": {
        "id": "nkrk3sXQPZiQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile our resnet model\n",
        "resnet_model.compile(loss=\"categorical_crossentropy\",\n",
        "                     optimizer=tfk.optimizers.Adam(),\n",
        "                     metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "riKn6L38PrEq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's fit our resnet model to the data (10 percent of 10 classes)\n",
        "resnet_history = resnet_model.fit(train_data_10_percent,\n",
        "                           epochs=5,\n",
        "                           steps_per_epoch=len(train_data_10_percent),\n",
        "                           validation_data=test_data,\n",
        "                           validation_steps=len(test_data),\n",
        "                           callbacks=[create_tensorboard_callback(dir_name=\"tensorflow_hub\",\n",
        "                                                                  experiment_name=\"resnet_v2_50\")])"
      ],
      "metadata": {
        "id": "aUUDkiMXQLXy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our transfer learning feature extractor model out performed all of the previous models we built by hand... (substantially) in a quicker training time and with only 10% of the training examples."
      ],
      "metadata": {
        "id": "zN1dig5wUJZp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's create a function to plot our loss curves...\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot the validation and training curves\n",
        "def plot_loss_curves(history):\n",
        "  \"\"\"\n",
        "  Returns seperate loss curves for training and validation metrics.\n",
        "\n",
        "  Args:\n",
        "    history: TensorFlow History object.\n",
        "\n",
        "  Returns:\n",
        "    Plot of training/validation loss and accuracy metrics.\n",
        "  \"\"\"\n",
        "  loss = history.history[\"loss\"]\n",
        "  val_loss = history.history[\"val_loss\"]\n",
        "  accuracy = history.history[\"accuracy\"]\n",
        "  val_accuracy = history.history[\"val_accuracy\"]\n",
        "  epochs = range(len(history.history[\"loss\"]))\n",
        "\n",
        "  # Plot loss\n",
        "  plt.plot(epochs, loss, label=\"training_loss\")\n",
        "  plt.plot(epochs, val_loss, label=\"val_loss\")\n",
        "  plt.title(\"Loss\")\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.legend()\n",
        "\n",
        "  # Plot accuracy\n",
        "  plt.figure()\n",
        "  plt.plot(epochs, accuracy, label=\"training_accuracy\")\n",
        "  plt.plot(epochs, val_accuracy, label=\"val_accuracy\")\n",
        "  plt.title(\"Accuracy\")\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.legend()"
      ],
      "metadata": {
        "id": "blTywE4GVTsC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_loss_curves(resnet_history)"
      ],
      "metadata": {
        "id": "F_SRb_JobozK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating and testing EfficientNet TensorFlow Hub Feature Extraction model"
      ],
      "metadata": {
        "id": "sbo4d3XjcBXI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create EfficientNet feature extractor model\n",
        "efficientnet_model = create_model(efficientnet_url,\n",
        "                                  num_classes=train_data_10_percent.num_classes)\n",
        "\n",
        "# Compile EfficientNet model\n",
        "efficientnet_model.compile(loss=\"categorical_crossentropy\",\n",
        "                           optimizer=tfk.optimizers.Adam(),\n",
        "                           metrics=[\"accuracy\"])\n",
        "\n",
        "# Fit EfficientNet model to 10% of training data\n",
        "efficientnet_history = efficientnet_model.fit(train_data_10_percent,\n",
        "                                              epochs=5,\n",
        "                                              steps_per_epoch=len(train_data_10_percent),\n",
        "                                              validation_data=test_data,\n",
        "                                              validation_steps=len(test_data),\n",
        "                                              callbacks=[create_tensorboard_callback(dir_name=\"tensorflow_hub\",\n",
        "                                                                                     experiment_name=\"efficientnet_b0\")])"
      ],
      "metadata": {
        "id": "2qB-5Dv_ubIx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_loss_curves(efficientnet_history)"
      ],
      "metadata": {
        "id": "1zPpK5XWxyQz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Different types of transfer learning\n",
        "\n",
        "* **\"As is\" transfer learning** - using an existing model with no changes what so ever (e.g. using ImageNet model on 1000 ImageNet classes, none of your own).\n",
        "* **\"Feature extraction\" transfer learning** - use the prelearned patterns of an existing model (e.g. EfficientNet_B0 trained on ImageNet) and adjust the output layer for your own problem (e.g. 1000 classes -> 10 classes of food)\n",
        "* **\"Fine-tuning\" transfer learning** - use the prelearned patterns of an existing model and \"fine-tune\" many or all of the underlying layers (including new output layers)."
      ],
      "metadata": {
        "id": "QL6m2gUyybrQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comparing our models' results using TensorBoard"
      ],
      "metadata": {
        "id": "xgjvBOL62OMJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Launch TensorBoard and see the results!\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir ./tensorflow_hub/"
      ],
      "metadata": {
        "id": "9ZFrDbu05yHs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}