{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN15TUWbZWLhERUWGD2CS0b",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zuhayerror3i8/TensorFlow-for-Deep-Learning-Bootcamp/blob/main/Section%2004%20-%20Neural%20network%20classification%20in%20TensorFlow/02_neural_network_classification_in_tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction to neural network classification with TensorFlow\n",
        "\n",
        "A classification is where you try to classify something as one thing or another.\n",
        "\n",
        "A few types of classification problems:\n",
        "* Binary classification\n",
        "* Multiclass classification\n",
        "* Multilabel classificaiton"
      ],
      "metadata": {
        "id": "4y0TWG3M1hBh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating data to view and fit"
      ],
      "metadata": {
        "id": "CiWvdOzz208I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_circles\n",
        "\n",
        "# Make 1000 examples\n",
        "n_samples = 1000\n",
        "\n",
        "# Create circles\n",
        "X, y = make_circles(n_samples,\n",
        "                    noise=0.03,\n",
        "                    random_state=42)"
      ],
      "metadata": {
        "id": "Ou29k4TG25Q1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the features\n",
        "X"
      ],
      "metadata": {
        "id": "opij5TLn3XgH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the labels\n",
        "y[:10]"
      ],
      "metadata": {
        "id": "kmFUxvxy3f-_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our data is little hard to understand right now... Let's visualize it!"
      ],
      "metadata": {
        "id": "zTdENSra4D7D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "circles = pd.DataFrame({\"X0\":X[:, 0], \"X1\":X[:, 1], \"label\":y})\n",
        "circles"
      ],
      "metadata": {
        "id": "fyyvio234NtR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize with a plot\n",
        "import matplotlib.pyplot as plt\n",
        "plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.RdYlBu)"
      ],
      "metadata": {
        "id": "VVySsNtY4rR_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Input and output shapes"
      ],
      "metadata": {
        "id": "o7knWYea53UY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the shapes of our features and labels\n",
        "X.shape, y.shape"
      ],
      "metadata": {
        "id": "pgN3Dxyq57Ux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# How many samples we are working with\n",
        "len(X), len(y)"
      ],
      "metadata": {
        "id": "vOWcsMO16GHV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# View the first example of features and labels\n",
        "X[0], y[0]"
      ],
      "metadata": {
        "id": "WBVttij56VAY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Steps in modelling\n",
        "\n",
        "The steps in modelling with TensorFlow are typically:\n",
        "\n",
        "1. Create or import a model\n",
        "2. Compile the model\n",
        "3. Fit the model\n",
        "4. Evaluate the model\n",
        "5. Tweak the model\n",
        "6. Evaluate..."
      ],
      "metadata": {
        "id": "bvLrxW_D6lz5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import TensorFlow\n",
        "import tensorflow as tf\n",
        "tf.__version__"
      ],
      "metadata": {
        "id": "-Doy-0i-7mj4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create the model using Sequential API\n",
        "model_1 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "model_1.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "                optimizer=tf.keras.optimizers.SGD(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# 3. Fit the model\n",
        "model_1.fit(X, y, epochs=5)"
      ],
      "metadata": {
        "id": "kEMIOYWi61xe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's try and improve our model by training for longer...\n",
        "model_1.fit(X, y, epochs=200, verbose=0)\n",
        "model_1.evaluate(X, y)"
      ],
      "metadata": {
        "id": "0dAxgq9q9qhh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since we're working on a binary classification problem and our model is getting around ~50% accuracy... It's performing as if it's guessing.\n",
        "\n",
        "So, let's step things up a notch and add an extra layer."
      ],
      "metadata": {
        "id": "DYVvXHVg-Qp3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step the random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create a model, this time with 2 layers\n",
        "model_2 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(1),\n",
        "    tf.keras.layers.Dense(1),\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "model_2.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "                optimizer=tf.keras.optimizers.SGD(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# 3. Fit the model\n",
        "model_2.fit(X, y, epochs=100, verbose=0)"
      ],
      "metadata": {
        "id": "wgVHez5p-1XN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Evaluate the model\n",
        "model_2.evaluate(X, y)"
      ],
      "metadata": {
        "id": "xKYClSir_3dX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Improving our model\n",
        "\n",
        "Let's look into our bag of tricks to see how we can improve our model.\n",
        "\n",
        "1. Create a model - we might want to add more layers or increase the number of hidden units within a layer.\n",
        "2. Compiling a model - here we might want to choose a different optimization function such as Adam instead of SGD.\n",
        "3. Fitting a model - perhaps we might fit our model for more epochs (leave it training for longer)."
      ],
      "metadata": {
        "id": "9UqrqgiUANLv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create the model (this time with 3 layers)\n",
        "model_3 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(100), # Add 100 dense neurons\n",
        "    tf.keras.layers.Dense(10), # add another leyer with 10 neurons\n",
        "    tf.keras.layers.Dense(1),\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "model_3.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# 3. Fit the model\n",
        "model_3.fit(X, y, epochs=100, verbose=0)"
      ],
      "metadata": {
        "id": "zlw9146PBz1d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Evaluate the model\n",
        "model_3.evaluate(X, y)"
      ],
      "metadata": {
        "id": "1Jacp31JC2GS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To visualize our model's predictions, let's create a function `plot_decision_boundary()`.\n",
        "\n",
        "This function will:\n",
        "* Take in a trained model, fetures (X) and labels (y).\n",
        "* Create a meshgrid of the different X values.\n",
        "* Make the predictions across the meshgrid.\n",
        "* Plot the predictions as well as a line between zones (where each unique class falls)."
      ],
      "metadata": {
        "id": "C7wp8c9xDZWu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "U2xd02QbJOL3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_decision_boundary(model, X, y):\n",
        "  \"\"\"\n",
        "  Plots the decision boundary created by a model predicting on X.\n",
        "  \"\"\"\n",
        "  # Define the axis boundaries of the plot and create a meshgrid\n",
        "  x_min, x_max = X[:, 0].min() - 0.1, X[:, 0].max() + 0.1\n",
        "  y_min, y_max = X[:, 1].min() - 0.1, X[:, 1].max() + 0.1\n",
        "  xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100),\n",
        "                       np.linspace(y_min, y_max, 100))\n",
        "\n",
        "  # Create X value (we're going to make predictions on these)\n",
        "  x_in = np.c_[xx.ravel(), yy.ravel()] # Stack 2D arrays together\n",
        "\n",
        "  # Make predictions\n",
        "  y_pred = model.predict(x_in)\n",
        "\n",
        "  # Check for multiclass\n",
        "  if len(y_pred[0]) > 1:\n",
        "    print(\"Doing multiclass classification\")\n",
        "\n",
        "    # We have to reshape our prediction to get them ready for plotting\n",
        "    y_pred = np.argmax(y_pred, axis=1).reshape(xx.shape)\n",
        "  else:\n",
        "    print(\"Doing binary classification\")\n",
        "    y_pred = np.round(y_pred).reshape(xx.shape)\n",
        "\n",
        "  # Plot the decision boundary\n",
        "  plt.contourf(xx, yy, y_pred, cmap=plt.cm.RdYlBu, alpha=0.7)\n",
        "  plt.scatter(X[:, 0], X[:, 1], c=y, s=40, cmap=plt.cm.RdYlBu)\n",
        "  plt.xlim(xx.min(), xx.max())\n",
        "  plt.ylim(yy.min(), yy.max())"
      ],
      "metadata": {
        "id": "oi5mxhteEinE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out the predictions our model is making\n",
        "plot_decision_boundary(model=model_3,\n",
        "                       X=X,\n",
        "                       y=y)"
      ],
      "metadata": {
        "id": "mqrwl4KjQs8_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's see if our model can be used for a regression problem...\n",
        "\n",
        "# Set the random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Create some regression data\n",
        "X_regression = tf.range(0, 1000, 5)\n",
        "y_regression = tf.range(100, 1100, 5) # y = X + 100\n",
        "\n",
        "# Split our regression data into training and test set\n",
        "X_reg_train = X_regression[:150]\n",
        "X_reg_test = X_regression[150:]\n",
        "y_reg_train = y_regression[:150]\n",
        "y_reg_test = y_regression[150:]\n",
        "\n",
        "# Fit our model to the regression data\n",
        "model_3.fit(tf.expand_dims(X_reg_train, axis=-1), y_reg_train, epochs=100)"
      ],
      "metadata": {
        "id": "u-A7mDjnTYTM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We compiled our model for a binary classification problem.\n",
        "\n",
        "But... We're now working on a regression problem. Let's change the model to suit our data."
      ],
      "metadata": {
        "id": "-E5XQOymVZq4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create the model\n",
        "model_3 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(100),\n",
        "    tf.keras.layers.Dense(10),\n",
        "    tf.keras.layers.Dense(1),\n",
        "])\n",
        "\n",
        "# 2. Compile the model, this time with a regression-specific loss function\n",
        "model_3.compile(loss=tf.keras.losses.mae,\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"mae\"])\n",
        "\n",
        "# 3. Fit the model\n",
        "model_3.fit(tf.expand_dims(X_reg_train, axis=-1), y_reg_train, epochs=100)"
      ],
      "metadata": {
        "id": "RELNNbDvVuSO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions with our trained model\n",
        "y_reg_preds = model_3.predict(X_reg_test)\n",
        "\n",
        "# Plot the model's predictions against our regression data\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.scatter(X_reg_train, y_reg_train, c=\"b\", label=\"Training data\")\n",
        "plt.scatter(X_reg_test, y_reg_test, c=\"g\", label=\"Test data\")\n",
        "plt.scatter(X_reg_test, y_reg_preds, c=\"r\", label=\"Predictions\")\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "bDTTQZ8aWuv7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The missing piece: Non-linearity"
      ],
      "metadata": {
        "id": "6MATBhgZYImm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create the model\n",
        "model_4 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(1, activation=tf.keras.activations.linear)\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "model_4.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# 3. Fit the model\n",
        "history = model_4.fit(X, y, epochs=100)"
      ],
      "metadata": {
        "id": "_oiioiGRZpTZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out our data\n",
        "plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.RdYlBu)"
      ],
      "metadata": {
        "id": "KxswxWoUbKWY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the decision boundary for our latest model\n",
        "plot_decision_boundary(model=model_4,\n",
        "                       X=X,\n",
        "                       y=y)"
      ],
      "metadata": {
        "id": "ZaeIfeEabaux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's try to build our first neural network with a non-linear activation function."
      ],
      "metadata": {
        "id": "FVgcUJg6cQS1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create a model with a non-linear activation\n",
        "model_5 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(1, activation=tf.keras.activations.relu)\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "model_5.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# 3. Fit the model\n",
        "history = model_5.fit(X, y, epochs=100)"
      ],
      "metadata": {
        "id": "n_ZoWYAOcdPG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Time to replicate the multi-layer neural network from TensorFlow playground in code...\n",
        "\n",
        "# Set the random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create the model\n",
        "model_6 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(4, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(4, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "model_6.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# 3. Fit the model\n",
        "history = model_6.fit(X, y, epochs=100)"
      ],
      "metadata": {
        "id": "hdlAJLLZehra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "model_6.evaluate(X, y)"
      ],
      "metadata": {
        "id": "Q-kTb_Qugmpf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# How do our model predictions look like?\n",
        "plot_decision_boundary(model_6, X, y)"
      ],
      "metadata": {
        "id": "GzA1rWadhE9G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create the model\n",
        "model_7 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(4, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(4, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "model_7.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# 3. Fit the model\n",
        "history = model_7.fit(X, y, epochs=100)"
      ],
      "metadata": {
        "id": "bTcJUasFh_cd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Evaluate our model\n",
        "model_7.evaluate(X, y)"
      ],
      "metadata": {
        "id": "fkJnIESDjS1u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's visualize our incredible metrics\n",
        "plot_decision_boundary(model_7, X, y)"
      ],
      "metadata": {
        "id": "OUhEqeisjef-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question:** What's wrong the predictions we've made? Are we really evaluating our model correctly? Hint: What data did the model learn on and what data did we predict on?\n",
        "\n",
        "**Note:** The combination of **linear (straight lines) and non-linear (non-straight lines) functions** is one of the key fundamentals of neural networks.\n",
        "\n",
        "Now we've discussed the concept of linear and non-linear functions (or lines), let's see them in action."
      ],
      "metadata": {
        "id": "SUFZ0N_ikYQC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a toy tensor (similar to the data we pass into our models)\n",
        "A = tf.cast(tf.range(-10, 10), tf.float32)\n",
        "A"
      ],
      "metadata": {
        "id": "4jKxlTJf1bVs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize our toy tensor\n",
        "plt.plot(A)"
      ],
      "metadata": {
        "id": "3XSACpte1s2_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's start by replicating sigmoid. sigmoid(x) = 1 / (1 + exp(-x))\n",
        "def sigmoid(x):\n",
        "  return 1 / (1 + tf.exp(-x))\n",
        "\n",
        "# Use the sigmoid function on our toy tensor\n",
        "sigmoid(A)"
      ],
      "metadata": {
        "id": "jBLSoh7Z1yZI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot our toy tensor transformed by sigmoid\n",
        "plt.plot(sigmoid(A))"
      ],
      "metadata": {
        "id": "vCGPLV1-2iR7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's recreate the relu function\n",
        "def relu(x):\n",
        "  return tf.maximum(0, x)\n",
        "\n",
        "# Pass our toy tensor to our custom relu function\n",
        "relu(A)"
      ],
      "metadata": {
        "id": "2gsjnFUP22C6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot ReLU-modified tensor\n",
        "plt.plot(relu(A))"
      ],
      "metadata": {
        "id": "RWkFgQfB3qZg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's create linear activation function\n",
        "tf.keras.activations.linear(A)"
      ],
      "metadata": {
        "id": "jhVRke3137oJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Does the linear activation function change anything?\n",
        "plt.plot(tf.keras.activations.linear(A))"
      ],
      "metadata": {
        "id": "7jnt-kkh4IdU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Does A even change?\n",
        "A == tf.keras.activations.linear(A)"
      ],
      "metadata": {
        "id": "v8MoTpCn4UpV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluating and improving our classification model\n",
        "\n",
        "So far we've been trianing and testing on the same dataset...\n",
        "\n",
        "However, in machine learning this is basically a sin.\n",
        "\n",
        "So, let's create a training and test set."
      ],
      "metadata": {
        "id": "a_caZVdf4eL7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check how many examples we have\n",
        "len(X)"
      ],
      "metadata": {
        "id": "bakcX9TP572-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split into training and test set\n",
        "X_train, y_train = X[:800], y[:800]\n",
        "X_test, y_test = X[800:], y[800:]\n",
        "\n",
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ],
      "metadata": {
        "id": "VfR_Bbvs6IcT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's recreate a model to fit on the training data and evaluate on the testing data\n",
        "\n",
        "# Set the random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create the model (same as model_7)\n",
        "model_8 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(4, activation='relu'),\n",
        "    tf.keras.layers.Dense(4, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid'),\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "model_8.compile(loss='binary_crossentropy',\n",
        "                optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# 3. Fit the model\n",
        "history = model_8.fit(X_train, y_train, epochs=25)"
      ],
      "metadata": {
        "id": "ZtoPqSUC6qOt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Evaluate the model on the test dataset\n",
        "model_8.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "id": "UHynC5nf8Ygv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the decison boundary for the training and test set\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.title(\"Train\")\n",
        "plot_decision_boundary(model_8, X=X_train, y=y_train)\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.title(\"Test\")\n",
        "plot_decision_boundary(model_8, X=X_test, y=y_test)"
      ],
      "metadata": {
        "id": "-PpOerLZ8rnw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot the loss (or training) curves"
      ],
      "metadata": {
        "id": "jn5UgJeW-SUG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the history object into a DataFrame\n",
        "pd.DataFrame(history.history)"
      ],
      "metadata": {
        "id": "uLTfCantBO15"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the loss curves\n",
        "pd.DataFrame(history.history).plot()\n",
        "plt.title(\"Model_8 loss curves\")"
      ],
      "metadata": {
        "id": "0nd9nsRDB3xR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:** For many problems, the loss function going down means the model is improving (the predictions it's making are getting closer to the ground truth labels)."
      ],
      "metadata": {
        "id": "9dIaL6fNCLGB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Finding the best learning rate\n",
        "\n",
        "To find the ideal learning rate (the learning rate where the loss decreses the most during training).\n",
        "\n",
        "We're going to use the following steps:\n",
        "* A learning rate **callback** - you can think of callback as an extra piece of functionality, you can add to your model *while* its trianing.\n",
        "* Another model (we could use the same as above, but we're practicing building models here).\n",
        "* A modified loss curves plot."
      ],
      "metadata": {
        "id": "sASg9BepC8av"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create a model (same as above)\n",
        "model_9 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(4, activation='relu'),\n",
        "    tf.keras.layers.Dense(4, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid'),\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "model_9.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# 3. Create a learning rate callback\n",
        "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lambda epoch: 1e-4 * 10 ** (epoch / 20))\n",
        "\n",
        "# 4. Fit the model (passing lr_scheduler callback)\n",
        "history_9 = model_9.fit(X_train,\n",
        "                        y_train,\n",
        "                        epochs=100,\n",
        "                        callbacks=[lr_scheduler])"
      ],
      "metadata": {
        "id": "ELiKubHcD7aP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checkout the history\n",
        "pd.DataFrame(history_9.history).plot(figsize=(10, 7), xlabel=\"epochs\")"
      ],
      "metadata": {
        "id": "mIkSEyWhGN45"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the learning rate versus the loss\n",
        "lrs = 1e-4 * 10 ** (tf.range(100) / 20)\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.semilogx(lrs, history_9.history[\"loss\"])\n",
        "plt.xlabel(\"Learning Rate\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Learning rate vs. Loss\")"
      ],
      "metadata": {
        "id": "U5AzGywUG5dJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example of other typical learning rate values:\n",
        "10 ** 0, 10 ** -1, 10 ** -2, 10 ** -3, 10 ** -4"
      ],
      "metadata": {
        "id": "p7hgTB4oHThg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's try using a higher *ideal* learning rate with the same model\n",
        "\n",
        "# Set the random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create the model\n",
        "model_10 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(4, activation='relu'),\n",
        "    tf.keras.layers.Dense(4, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "model_10.compile(loss='binary_crossentropy',\n",
        "                 optimizer=tf.keras.optimizers.Adam(learning_rate=0.02),\n",
        "                 metrics=[\"accuracy\"])\n",
        "\n",
        "# 3. Fit the model for 20 epochs (5 less than before)\n",
        "history_10 = model_10.fit(X_train, y_train, epochs=20)"
      ],
      "metadata": {
        "id": "UL2wH7QbJhLx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate model_10 on the test dataset\n",
        "model_10.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "id": "mvrsiQESLNiF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate model_8 on the test dataset\n",
        "model_8.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "id": "PITwKFgXLWQK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the decision boundary for the training and test set\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.title(\"Train\")\n",
        "plot_decision_boundary(model_10, X=X_train, y=y_train)\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.title(\"Test\")\n",
        "plot_decision_boundary(model_10, X=X_test, y=y_test)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "x7M7uAo5LqF_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## More classification evatuation methods\n",
        "\n",
        "Alongside visualizing our models results as much as possible, there are a handful of other classification evaluation methods & metrics you should be familiar with:\n",
        "* Accuracy\n",
        "* Precision\n",
        "* Recall\n",
        "* F1-score\n",
        "* Confusion matrix\n",
        "* Classification report (from scikit-learn)"
      ],
      "metadata": {
        "id": "Ai1YNXL0NrXJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the accuracy of our model_10\n",
        "loss, accuracy = model_10.evaluate(X_test, y_test)\n",
        "print(f\"Model loss on the test set: {loss}\")\n",
        "print(f\"Model accuracy on the test set: {(accuracy * 100):.2f}%\")"
      ],
      "metadata": {
        "id": "1V7dQ0l0OdTq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "How about a confusion matrix?"
      ],
      "metadata": {
        "id": "zoruxBEQPIis"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model_10.predict(X_test)\n",
        "\n",
        "# Create confusion matrix\n",
        "confusion_matrix(y_test, y_pred)"
      ],
      "metadata": {
        "id": "gDK0GANoPNqD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test[:10]"
      ],
      "metadata": {
        "id": "6gFdpENMTx7m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred[:10]"
      ],
      "metadata": {
        "id": "qtU6KuU1Tz44"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Oppps... Looks like our prediction array has come out in **prediction probability** form... The standard output from the sigmoid (or softmax) activation function."
      ],
      "metadata": {
        "id": "CdH3D3KSUGPl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert prediction probabilities to binary format and view the first 10\n",
        "tf.round(y_pred)[:10]"
      ],
      "metadata": {
        "id": "EHKb9iBWU4CM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create confusion matrix\n",
        "confusion_matrix(y_test, tf.round(y_pred))"
      ],
      "metadata": {
        "id": "pyBGG53UVUNK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "How about we prettify our confusion matrix?"
      ],
      "metadata": {
        "id": "obWkOD_CV60X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Note: The confusion matrix code we're about to write is a remix of scikit-learn's plot_confusion_matrix\n",
        "\n",
        "import itertools\n",
        "\n",
        "figsize = (10, 10)\n",
        "\n",
        "# Create the confusion matrix\n",
        "cm = confusion_matrix(y_test, tf.round(y_pred))\n",
        "cm_norm = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis] # normalize our confusion matrix\n",
        "n_classes = cm.shape[0]\n",
        "\n",
        "# Let's prettify it\n",
        "fig, ax = plt.subplots(figsize=figsize)\n",
        "\n",
        "# Create a matrix plot\n",
        "cax = ax.matshow(cm, cmap=plt.cm.Blues)\n",
        "fig.colorbar(cax)\n",
        "\n",
        "# Create classes\n",
        "classes = False\n",
        "\n",
        "if classes:\n",
        "  labels = classes\n",
        "else:\n",
        "  labels = np.arange(cm.shape[0])\n",
        "\n",
        "# Label the axes\n",
        "ax.set(title=\"Confusion Matrix\",\n",
        "       xlabel=\"Predicted Label\",\n",
        "       ylabel=\"True Label\",\n",
        "       xticks=np.arange(n_classes),\n",
        "       yticks=np.arange(n_classes),\n",
        "       xticklabels=labels,\n",
        "       yticklabels=labels)\n",
        "\n",
        "# Set x-axis labels to bottom\n",
        "ax.xaxis.set_label_position(\"bottom\")\n",
        "ax.xaxis.tick_bottom()\n",
        "\n",
        "# Adjust label size\n",
        "ax.yaxis.label.set_size(20)\n",
        "ax.xaxis.label.set_size(20)\n",
        "ax.title.set_size(20)\n",
        "\n",
        "# Set threshold for different colors\n",
        "threshold = (cm.max() + cm.min()) / 2.\n",
        "\n",
        "# Plot the text on each cell\n",
        "for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "  plt.text(j, i, f\"{cm[i, j]} ({cm_norm[i, j] * 100:.1f}%)\",\n",
        "           horizontalalignment=\"center\",\n",
        "           color=\"white\" if cm[i, j] > threshold else \"black\",\n",
        "           size=15)"
      ],
      "metadata": {
        "id": "qSrXTRsCWA0T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Working with a larger example (multiclass classification)\n",
        "\n",
        "When you have more than two classes as an option, it's known as **multiclass classification**.\n",
        "* This means if you have 3 different classes, it's multiclass classification.\n",
        "* It also means if you have 100 different classes, it's multiclass classification.\n",
        "\n",
        "To practice multiclass classification, we're going to build a neural network to classify images of different items of clothing."
      ],
      "metadata": {
        "id": "LOEVMEwegJSt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparing the data"
      ],
      "metadata": {
        "id": "NTjpueA27xWV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "# The data has already been sorted into training and test set for us\n",
        "(train_data, train_labels), (test_data, test_labels) = fashion_mnist.load_data()"
      ],
      "metadata": {
        "id": "Ty00Jvdjh201"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show the first training example\n",
        "print(f\"Training sample:\\n{train_data[0]}\\n\")\n",
        "print(f\"Training label:\\n{train_labels[0]}\\n\")"
      ],
      "metadata": {
        "id": "wQZtAaIGjv_a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the shape of a single example\n",
        "train_data[0].shape, train_labels[0].shape"
      ],
      "metadata": {
        "id": "L5NitUP9kZFw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot a single sample\n",
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(train_data[0])"
      ],
      "metadata": {
        "id": "g8EFwZlXkjzc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out the label of a single example\n",
        "train_labels[7]"
      ],
      "metadata": {
        "id": "taQ4dHnLkywu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a small list so we can index onto our training labels so they're human-readable\n",
        "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n",
        "\n",
        "len(class_names)"
      ],
      "metadata": {
        "id": "j-q0gogqlOuW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot an example image and its label\n",
        "index_of_choice = 17\n",
        "plt.imshow(train_data[index_of_choice], cmap=plt.cm.binary)\n",
        "plt.title(class_names[train_labels[index_of_choice]])"
      ],
      "metadata": {
        "id": "UUho4Opsl9rL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot multiple random images of fashion MNIST\n",
        "import random\n",
        "plt.figure(figsize=(7, 7))\n",
        "for i in range(4):\n",
        "  ax = plt.subplot(2, 2, i+1)\n",
        "  rand_index = random.choice(range(len(train_data)))\n",
        "  plt.imshow(train_data[rand_index], cmap=plt.cm.binary)\n",
        "  plt.title(class_names[train_labels[rand_index]])\n",
        "  plt.axis(False)"
      ],
      "metadata": {
        "id": "w7eXMwPYmpBa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building a multiclass classification model\n",
        "\n",
        "For our multiclass classification model, we can use a similar architecture to our binary classifiers, however, we're going to have to tweak a few things:\n",
        "* Input shape = 28 X 28 (the shape of one image).\n",
        "* Output shape = 10 (one per class or clothing).\n",
        "* Loss function = tf.keras.losses.CategoricalCrossentropy()\n",
        "  * If your labels are one-hot encoded, use CategoricalCrossentropy()\n",
        "  * If your labels are in integer form, use SparseCategoricalCrossentropy()\n",
        "* Output layer activation = softmax (not sigmoid)"
      ],
      "metadata": {
        "id": "1t8HCcKwnzO2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create the model\n",
        "model_11 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    tf.keras.layers.Dense(4, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(4, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "model_11.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "                 optimizer=tf.keras.optimizers.Adam(),\n",
        "                 metrics=[\"accuracy\"])\n",
        "\n",
        "# 3. Fit the model\n",
        "non_norm_history = model_11.fit(train_data,\n",
        "                                train_labels,\n",
        "                                epochs=10,\n",
        "                                validation_data=(test_data, test_labels))"
      ],
      "metadata": {
        "id": "-q6WREHnpAro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the model summary\n",
        "model_11.summary()"
      ],
      "metadata": {
        "id": "HMWfBB1juQQs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the min and max values of the training data\n",
        "train_data.min(), train_data.max()"
      ],
      "metadata": {
        "id": "qJs_OJitukRD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Normalizing our data"
      ],
      "metadata": {
        "id": "RcgChdY673g9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Neural networks prefer data to be scaled (or normalized), this means they like to have numbers in the tensors they try to find patterns between 0 & 1."
      ],
      "metadata": {
        "id": "keXS9WCxut7E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We can get our training and testing data between 0 & 1 by dividing by the maximum\n",
        "train_data_norm = train_data / 255.\n",
        "test_data_norm = test_data / 255.\n",
        "\n",
        "# Check the min and max values of the scaled training data\n",
        "train_data_norm.min(), train_data_norm.max()"
      ],
      "metadata": {
        "id": "6BPNXDbTvJN7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now our data is normalized, let's build a model to find patterns in it\n",
        "\n",
        "# Set the random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create a model (same as model_11)\n",
        "model_12 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    tf.keras.layers.Dense(4, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(4, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "model_12.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "                 optimizer=tf.keras.optimizers.Adam(),\n",
        "                 metrics=[\"accuracy\"])\n",
        "\n",
        "# 3. Fit the model\n",
        "norm_history = model_12.fit(train_data_norm,\n",
        "                            train_labels,\n",
        "                            epochs=10,\n",
        "                            validation_data=(test_data_norm, test_labels))"
      ],
      "metadata": {
        "id": "8PSgOq7hv48t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Note:** Neural networks tend to prefer data in numerical form as well as scaled/normalized (numbers between 0 & 1)."
      ],
      "metadata": {
        "id": "RfavypUmxg9w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Plot non-normalized data loss curves\n",
        "pd.DataFrame(non_norm_history.history).plot(title=\"Non-normalized data\")\n",
        "\n",
        "# Plot normalized data loss curves\n",
        "pd.DataFrame(norm_history.history).plot(title=\"Normalized data\")"
      ],
      "metadata": {
        "id": "pX3E9qxyx11R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Note:** The same model with even *slightly* different data can produce *dramatically* different results. So, when you're comparing models, it's important to make sure you're comparing them on the same criteria (e.g. same architecture but different data or same data but different architecture)."
      ],
      "metadata": {
        "id": "YYWKklPEyiyJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Finding the ideal learning rate"
      ],
      "metadata": {
        "id": "UqvBc5vHziOO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create the model\n",
        "model_13 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    tf.keras.layers.Dense(4, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(4, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(10, activation=\"softmax\"),\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "model_13.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "                 optimizer=tf.keras.optimizers.Adam(),\n",
        "                 metrics=[\"accuracy\"])\n",
        "\n",
        "# 3. Create the learning rate callback\n",
        "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lambda epoch: 1e-3 * 10 ** (epoch / 20))\n",
        "\n",
        "# 4. Fit the model\n",
        "lr_history = model_13.fit(train_data_norm,\n",
        "                          train_labels,\n",
        "                          epochs=40,\n",
        "                          validation_data=(test_data_norm, test_labels),\n",
        "                          callbacks=[lr_scheduler])"
      ],
      "metadata": {
        "id": "0CmBCgQdzn76"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the learning rate decay curve\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "lrs = 1e-3 * (10 ** (tf.range(40) / 20))\n",
        "plt.semilogx(lrs, lr_history.history[\"loss\"])\n",
        "plt.xlabel(\"Learning rate\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Finding the ideal learning rate\")"
      ],
      "metadata": {
        "id": "jOB9o4v51XOn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's refit a model with the ideal learning rate\n",
        "\n",
        "# Set the random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create the model\n",
        "model_14 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    tf.keras.layers.Dense(4, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(4, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "model_14.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "                 optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "                 metrics=[\"accuracy\"])\n",
        "\n",
        "# 3. Fit the model\n",
        "model_14.fit(train_data_norm,\n",
        "             train_labels,\n",
        "             epochs=20,\n",
        "             validation_data=(test_data_norm, test_labels))"
      ],
      "metadata": {
        "id": "ZX56R_U-2ucc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluating our multiclass classification model\n",
        "\n",
        "To evaluate our multiclass classification model we could:\n",
        "* Evaluate its performance using other classification metrics (such as a confusion matrix).\n",
        "* Assess some of its predictions (through visualizations).\n",
        "* Improve its results (by training it for longer or changing the architecture).\n",
        "* Save and export it to use in an application.\n",
        "\n",
        "Let's go through the top 2..."
      ],
      "metadata": {
        "id": "0kh7uLXa8JWr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a confusion matrix\n",
        "\n",
        "import itertools\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def make_confusion_matrix(y_true, y_pred, classes=None, figsize=(10, 10), text_size=15):\n",
        "  # Create the confusion matrix\n",
        "  cm = confusion_matrix(y_true, y_pred)\n",
        "  cm_norm = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis] # normalize our confusion matrix\n",
        "  n_classes = cm.shape[0]\n",
        "\n",
        "  # Let's prettify it\n",
        "  fig, ax = plt.subplots(figsize=figsize)\n",
        "\n",
        "  # Create a matrix plot\n",
        "  cax = ax.matshow(cm, cmap=plt.cm.Blues)\n",
        "  fig.colorbar(cax)\n",
        "\n",
        "  # Set labels to be classes\n",
        "  if classes:\n",
        "    labels = classes\n",
        "  else:\n",
        "    labels = np.arange(cm.shape[0])\n",
        "\n",
        "  # Label the axes\n",
        "  ax.set(title=\"Confusion Matrix\",\n",
        "        xlabel=\"Predicted Label\",\n",
        "        ylabel=\"True Label\",\n",
        "        xticks=np.arange(n_classes),\n",
        "        yticks=np.arange(n_classes),\n",
        "        xticklabels=labels,\n",
        "        yticklabels=labels)\n",
        "\n",
        "  # Set x-axis labels to bottom\n",
        "  ax.xaxis.set_label_position(\"bottom\")\n",
        "  ax.xaxis.tick_bottom()\n",
        "\n",
        "  # Adjust label size\n",
        "  ax.yaxis.label.set_size(text_size)\n",
        "  ax.xaxis.label.set_size(text_size)\n",
        "  ax.title.set_size(text_size)\n",
        "\n",
        "  # Set threshold for different colors\n",
        "  threshold = (cm.max() + cm.min()) / 2.\n",
        "\n",
        "  # Plot the text on each cell\n",
        "  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "    plt.text(j, i, f\"{cm[i, j]} ({cm_norm[i, j] * 100:.1f}%)\",\n",
        "            horizontalalignment=\"center\",\n",
        "            color=\"white\" if cm[i, j] > threshold else \"black\",\n",
        "            size=text_size)"
      ],
      "metadata": {
        "id": "0H163_zw9Eqr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names"
      ],
      "metadata": {
        "id": "dqbsZ-Ve--1A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make some predictions with our model\n",
        "y_prob = model_14.predict(test_data_norm) # prob is the short for \"prediction probability\"\n",
        "\n",
        "# View the first 5 predictions\n",
        "y_prob[:5]"
      ],
      "metadata": {
        "id": "Mx0czmUP_B8j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Note:** Remember to make predictions on the same kind of data your model was trained on (e.g. if your model was trained on normalized data, you need to make predictions on normalized data)."
      ],
      "metadata": {
        "id": "pWUYQ18I_5ca"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_prob[0], tf.argmax(y_prob[0]), class_names[tf.argmax(y_prob[0])]"
      ],
      "metadata": {
        "id": "SttL5Eg6Ahnu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert all of the prediction probabilities into integers\n",
        "y_pred = y_prob.argmax(axis=1)\n",
        "\n",
        "# View the first 10 predictions labels\n",
        "y_pred[:10]"
      ],
      "metadata": {
        "id": "Px7Wc_66A5se"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_labels"
      ],
      "metadata": {
        "id": "mkF8kulsBRZf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix(y_true=test_labels,\n",
        "                 y_pred=y_pred)"
      ],
      "metadata": {
        "id": "t_60FH85Bb4Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a prettier confusion matrix\n",
        "make_confusion_matrix(y_true=test_labels,\n",
        "                      y_pred=y_pred,\n",
        "                      classes=class_names,\n",
        "                      figsize=(17, 17),\n",
        "                      text_size=10)"
      ],
      "metadata": {
        "id": "bUEodzaUBz05"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Note:** Often when working with images and other forms of visual data. it's a good idea to visualize as much as possible to develop a further understanding of the data and the inputs and outputs of your models.\n",
        "\n",
        "How about we create a fun little function for:\n",
        "* Plot a random image.\n",
        "* Make a prediction on said image\n",
        "* Label the plot with the truth label & the predicted label."
      ],
      "metadata": {
        "id": "8Sr1T_GiDIYv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def plot_random_image(model, images, true_labels, classes):\n",
        "  \"\"\"\n",
        "  Picks a random image, plots it and labels it with a prediction and truth label.\n",
        "  \"\"\"\n",
        "  # Set up random integer\n",
        "  i = random.randint(0, len(images))\n",
        "\n",
        "  # Create predictions and targets\n",
        "  target_image = images[i]\n",
        "  pred_prob = model.predict(target_image.reshape(1, 28, 28))\n",
        "  pred_label = classes[pred_prob.argmax()]\n",
        "  true_label = classes[true_labels[i]]\n",
        "\n",
        "  # Plot the image\n",
        "  plt.imshow(target_image, cmap=plt.cm.binary)\n",
        "\n",
        "  # Change the color of the title depending on if the prediction is right or wrong\n",
        "  if pred_label == true_label:\n",
        "    color = \"green\"\n",
        "  else:\n",
        "    color = \"red\"\n",
        "\n",
        "  # Add xlabel information (prediction/true label)\n",
        "  plt.xlabel(\"Pred: {} {:2.0f}% (True: {})\".format(pred_label,\n",
        "                                                   100 * tf.reduce_max(pred_prob),\n",
        "                                                   true_label),\n",
        "             color=color) # Set the color to green or red based on if the prediction is right or wrong"
      ],
      "metadata": {
        "id": "FN6GKOBVD2Tw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out a random image as well as its prediction\n",
        "plot_random_image(model=model_14,\n",
        "                  images=test_data_norm, # Always make predictions on the same kind of data your model was trained on\n",
        "                  true_labels=test_labels,\n",
        "                  classes=class_names)"
      ],
      "metadata": {
        "id": "KOnEx6MyJhto"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What patterns are our model learning?"
      ],
      "metadata": {
        "id": "3R8_YhOXK0-7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the layers of our most recent model\n",
        "model_14.layers"
      ],
      "metadata": {
        "id": "nvM_-ZB3LERP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract a particular layer\n",
        "model_14.layers[1]"
      ],
      "metadata": {
        "id": "nukl6GaHLQq8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the patterns of a layer in our network\n",
        "weights, biases = model_14.layers[1].get_weights()\n",
        "\n",
        "# Shapes\n",
        "weights, weights.shape"
      ],
      "metadata": {
        "id": "MSmHgyPaLaGm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_14.summary()"
      ],
      "metadata": {
        "id": "c6TPBYNcMCke"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's check out the bias vector..."
      ],
      "metadata": {
        "id": "_Y5v1u5vM82c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Bias and biases shapes\n",
        "biases, biases.shape"
      ],
      "metadata": {
        "id": "W_GRNhLDNB68"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Every neuron has a bias vector. Each of these is paired with a weights matrix.\n",
        "\n",
        "The bias vector gets initialized as zeros (at least in the case of a TensorFlow Dense Layer).\n",
        "\n",
        "The bias vector dectates how much the patterns within the corresponding weights matrix should influence the next layer."
      ],
      "metadata": {
        "id": "AsSq-FW4NTAy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_14.summary()"
      ],
      "metadata": {
        "id": "EEEuKArmOJrd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's check out another way of viewing our deep learning models\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "# See the inputs and outputs of each layer\n",
        "plot_model(model_14, show_shapes=True)"
      ],
      "metadata": {
        "id": "4m6fVz0COhAS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}