{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP3M1le56ajUzZNkm7nZzib",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zuhayerror3i8/TensorFlow-for-Deep-Learning-Bootcamp/blob/main/Section%2009%20-%20Milestone%20Project%2001%20(Food%20Vision%20Big)/07_milestone_project_01_(food_vision_big).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Milestone Project 01 (Food Vision Big)"
      ],
      "metadata": {
        "id": "2pMXQhutjd7V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check GPU"
      ],
      "metadata": {
        "id": "LQnd-KEYF7Df"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi -L"
      ],
      "metadata": {
        "id": "6VDPP0hKGTzQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get helper functions"
      ],
      "metadata": {
        "id": "AVOTeZM4G5_6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download helper functions script\n",
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/refs/heads/main/extras/helper_functions.py"
      ],
      "metadata": {
        "id": "ywTqp3oXG-Xs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import series of helper functions for the notebook\n",
        "from helper_functions import create_tensorboard_callback, plot_loss_curves, compare_historys"
      ],
      "metadata": {
        "id": "DnK62dY2HJfc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Use TensorFlow Datasets to Download Data"
      ],
      "metadata": {
        "id": "dU79qTuaHrYz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get TensorFlow Datasets\n",
        "import tensorflow_datasets as tfds"
      ],
      "metadata": {
        "id": "kl0tGU09HwpK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List of all available datasets\n",
        "datasets_list = tfds.list_builders() # Get all the available datasets in TFDS\n",
        "print(\"food101\" in datasets_list) # Is our target dataset in the list of TFDS datasets?"
      ],
      "metadata": {
        "id": "9jnNqGaDInk0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load in the data (takes almost 15minutes in Google Colab)\n",
        "(train_data, test_data), ds_info = tfds.load(name=\"food101\",\n",
        "                                             split=[\"train\", \"validation\"],\n",
        "                                             shuffle_files=True,\n",
        "                                             as_supervised=True, # Data gets returned in tuple format (data, label)\n",
        "                                             with_info=True)"
      ],
      "metadata": {
        "id": "rabXNYO0LLQP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exploring the Food101 data from TensorFlow Datasets\n",
        "\n",
        "To become with our data, we want to find:\n",
        "\n",
        "* Class names.\n",
        "* The shape of our input data (image tensors).\n",
        "* The datatype of our input data.\n",
        "* What the labels look like (e.g. are they one-hot encoded or are they label encoded).\n",
        "* Do the labels match up with the class names?"
      ],
      "metadata": {
        "id": "vcmbxkD2NiuA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Features of Food101 from TFDS\n",
        "ds_info.features"
      ],
      "metadata": {
        "id": "Ct0xQV-GNCOR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the class names\n",
        "class_names = ds_info.features[\"label\"].names\n",
        "class_names[:10]"
      ],
      "metadata": {
        "id": "Rq0Szz60NPo2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Take one sample of the train data\n",
        "train_one_sample = train_data.take(1) # Samples are in format (image_tensor, label)"
      ],
      "metadata": {
        "id": "ny4j6CdRNfbl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# What does one sample of our training data look like?\n",
        "train_one_sample"
      ],
      "metadata": {
        "id": "qbuKBBhOOzCl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Output info about our training sample\n",
        "for image, label in train_one_sample:\n",
        "  print(f\"\"\"\n",
        "  Image shape: {image.shape},\n",
        "  Image datatype: {image.dtype},\n",
        "  Target class from Food101 (tensor form): {label},\n",
        "  Class name (str form): {class_names[label.numpy()]}\n",
        "  \"\"\")"
      ],
      "metadata": {
        "id": "65xfA8qSO_PA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# What does our image tensor from TFDS's Food101 look like?\n",
        "image"
      ],
      "metadata": {
        "id": "5EGICnoOPxer"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "xEw84SlPQRyh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# What are the min and max values of our image tensor?\n",
        "tf.reduce_min(image), tf.reduce_max(image)"
      ],
      "metadata": {
        "id": "h4R01BlXQBBL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot an image from TensorFlow Datasets"
      ],
      "metadata": {
        "id": "h8bTzQV7QcHU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot an image tensor\n",
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(image)\n",
        "plt.title(class_names[label.numpy()]) # Add title to image to verify the label is associated with the right image\n",
        "plt.axis(False)"
      ],
      "metadata": {
        "id": "34PBFnR3QzkF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create preprocessing functions for our data\n",
        "\n",
        "Neural networks perform best when data is in a certain way (e.g. batched, normalized, etc).\n",
        "\n",
        "However, not all data (including data from TensorFlow Datasets) comes like this.\n",
        "\n",
        "So, in order to get it ready for a neural network, you'll often have to write preprocessing functions and map it to your data.\n",
        "\n",
        "What we know about our data:\n",
        "\n",
        "* In `uint8` datatype.\n",
        "* Comprised of all different size tensors (different sized images).\n",
        "* Not scaled (the pixel values are between 0 & 255).\n",
        "\n",
        "What we know models like:\n",
        "\n",
        "* Data in `float32` dtype (or for mixed precision `float16` and `float32`).\n",
        "* For batches, TensorFlow likes all of the tensors within a batch to be of the same size.\n",
        "* Scaled (values between 0 & 1) also called normalized tensors generally perform better.\n",
        "\n",
        "With these points in mind, we've got a few things we can tackle with a preprocessing function.\n",
        "\n",
        "Since, we're going to use and EfficientNetBX pretrained model form `tf.keras.applications` we don't need to rescale our data (these architectures have rescaling built-in).\n",
        "\n",
        "This means our function needs to:\n",
        "1. Reshape our images to all the same size\n",
        "2. Convert the dtype of our image tensors from `uint8` to `float32`."
      ],
      "metadata": {
        "id": "3zeCbmviSCJo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a function for preprocessing images\n",
        "def preprocess_img(image, label, img_shape=224):\n",
        "  \"\"\"\n",
        "  Converts image datatype from 'uint8' -> 'float32' and reshapes image to [img_shape, img_shape, color_channels]\n",
        "  \"\"\"\n",
        "  image = tf.image.resize(image, [img_shape, img_shape]) # Reshape target image\n",
        "  # image = image/255. # Scale image values (not required with EfficientNetBX models from tf.keras.applications)\n",
        "  return tf.cast(image, tf.float32), label # Returns (float32_image, label) tuple"
      ],
      "metadata": {
        "id": "H3A85uw0U0rx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess a single sample image and check the outputs\n",
        "preprocessed_img = preprocess_img(image, label)[0]\n",
        "print(f\"Image before preprocessing:\\n {image[:2]}..., \\nShape: {image.shape}, \\nDatatype: {image.dtype}\\n\")\n",
        "print(f\"Image after preprocessing:\\n {preprocessed_img[:2]}..., \\nShape: {preprocessed_img.shape}, \\nDatatype: {preprocessed_img.dtype}\")"
      ],
      "metadata": {
        "id": "iXIIvYPRVzx_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Batch & prepare datasets\n",
        "\n",
        "We're now going to make our data input pipeline run really fast."
      ],
      "metadata": {
        "id": "4te7TByfXwKv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Map preprocessing function to training data (and parallelize)\n",
        "train_data = train_data.map(map_func=preprocess_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "# Shuffle train_data and turn it into batches and prefetch it (load it faster)\n",
        "train_data = train_data.shuffle(buffer_size=1000).batch(batch_size=32).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "\n",
        "# Map preprocessing function to test data\n",
        "test_data = test_data.map(preprocess_img, num_parallel_calls=tf.data.AUTOTUNE).batch(batch_size=32).prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "raiE12VFYQs5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, test_data"
      ],
      "metadata": {
        "id": "FJXy-k0gayMf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> \"Hey TensorFlow, map this preprocessing function (`preprocess_img`) across our training dataset, then shuffle a number of elements and then batch them together and finally, make sure you prepare new batches (prefetch) whilst the model is looking through (finding patterns) the current batch.\""
      ],
      "metadata": {
        "id": "tjPnc79ubOxW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create modelling callbacks\n",
        "\n",
        "We're going to create a couple of callbacks to help us while our model trains:\n",
        "\n",
        "* TensorBoard callback to log training results (So, we can visualize them later if needed).\n",
        "* ModelCheckpoint callback to save our model's progress after feature extraction."
      ],
      "metadata": {
        "id": "l-9oAzV0dBpg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create ModelCheckpoint callback to save a model's progress during training\n",
        "checkpoint_path = \"model_checkpoints/cp.weights.h5\"\n",
        "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,\n",
        "                                                      monitor=\"val_acc\",\n",
        "                                                      save_best_only=True,\n",
        "                                                      save_weights_only=True,\n",
        "                                                      verbose=0) # Don't print wheather or not model is being saved"
      ],
      "metadata": {
        "id": "HIlPVbjDdE48"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup mixed precision training\n",
        "\n",
        "First and foremost, for a deeper understanding of mixed precision training, check out the TensorFlow guide for mixed precision:\n",
        "https://www.tensorflow.org/guide/mixed_precision\n",
        "\n",
        "Mixed precision utilizes a combination of `float32` and `float16` data types to speed up model performance."
      ],
      "metadata": {
        "id": "7upuNo5af0tp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn on mixed precision training\n",
        "from tensorflow.keras import mixed_precision\n",
        "\n",
        "mixed_precision.set_global_policy(\"mixed_float16\") # Set global data policy to mixed precision"
      ],
      "metadata": {
        "id": "jTXuF1_Ege2c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mixed_precision.global_policy()"
      ],
      "metadata": {
        "id": "EGwlvFi6ieQ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build feature extraction model"
      ],
      "metadata": {
        "id": "Hov531jFnWIp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "# Create base model\n",
        "input_shape = (224, 224, 3)\n",
        "base_model = tf.keras.applications.EfficientNetB0(include_top=False)\n",
        "base_model.trainable = False\n",
        "\n",
        "# Create functional model\n",
        "inputs = layers.Input(shape=input_shape, name=\"input_layer\")\n",
        "\n",
        "# Note: EfficientNetBX models have rescaling built-in. But if your model doesn't, you can have a layer like below\n",
        "# x = layers.Rescaling(1./255)(x)\n",
        "x = base_model(inputs, training=False) # Makes sure layers which should be in inference mode only stay like that\n",
        "x = layers.GlobalAveragePooling2D()(x)\n",
        "x = layers.Dense(len(class_names))(x)\n",
        "outputs = layers.Activation(\"softmax\", dtype=tf.float32, name=\"softmax_float32\")(x)\n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=tf.keras.optimizers.Adam(),\n",
        "              metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "FNY6rNPznY76"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "8mE6tHPNqPSI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Checking layer dtype policies (are we using mixed precision?)"
      ],
      "metadata": {
        "id": "ZhZvH2wMrqpb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the dtype_policy attributes of layers in our model\n",
        "for layer in model.layers:\n",
        "  print(layer.name, layer.trainable, layer.dtype, layer.dtype_policy)"
      ],
      "metadata": {
        "id": "Bk7hFKpJrirf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in model.layers[1].layers:\n",
        "  print(layer.name, layer.trainable, layer.dtype, layer.dtype_policy)"
      ],
      "metadata": {
        "id": "5jj0XtSsslq8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fit the feature extraction model\n",
        "\n",
        "If our goal is to fine-tune a pretrained model, the general order of doing things is:\n",
        "\n",
        "1. Build a feature extraction model (train a couple of output layers with base layers frozen).\n",
        "2. Fine-tune some of the frozen layers."
      ],
      "metadata": {
        "id": "mHY26SzjtfsK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the feature extraction model with callbacks\n",
        "history_101_food_classes_feature_extract = model.fit(train_data,\n",
        "                                                     epochs=3,\n",
        "                                                     steps_per_epoch=len(train_data),\n",
        "                                                     validation_data=test_data,\n",
        "                                                     validation_steps=int(0.15 * len(test_data)),\n",
        "                                                     callbacks=[create_tensorboard_callback(\"training_logs\",\n",
        "                                                                                            \"efficientnetb0_101_classes_all_data_feature_extract\"),\n",
        "                                                                model_checkpoint])"
      ],
      "metadata": {
        "id": "z5wCEM_xuTDZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate model on whole test dataset\n",
        "results_feature_extract_model = model.evaluate(test_data)"
      ],
      "metadata": {
        "id": "_LO99z4tz1_I"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}