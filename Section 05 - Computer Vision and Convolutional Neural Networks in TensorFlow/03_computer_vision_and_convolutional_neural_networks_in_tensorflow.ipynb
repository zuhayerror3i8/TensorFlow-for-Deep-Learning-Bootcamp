{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNEu+2D+IGnOlbAicCccLMP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zuhayerror3i8/TensorFlow-for-Deep-Learning-Bootcamp/blob/main/Section%2005%20-%20Computer%20Vision%20and%20Convolutional%20Neural%20Networks%20in%20TensorFlow/03_computer_vision_and_convolutional_neural_networks_in_tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction to Convolutional Neural Networks and Computer Vision with TensorFlow\n",
        "\n",
        "Computer vision is the practice of writing algorithms which can discover patterns in visual data. Such as the camera of a self-driving car recognizing the car in front."
      ],
      "metadata": {
        "id": "ERTfdAmgZRAD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get the data\n",
        "\n",
        "The images we're working with are from the Food 101 dataset (101 different classes of food):\n",
        "https://www.kaggle.com/datasets/dansbecker/food-101\n",
        "\n",
        "However we've modified it to only use two classes (pizza & steak) using the image data modification notebook:\n",
        "https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/extras/image_data_modification.ipynb\n",
        "\n",
        "> **Note:** We start with a smaller dataset... So, we can experiment quickly and figure out what works (or better yet what doesn't work) before scaling up."
      ],
      "metadata": {
        "id": "fAVZaQQ1aNHp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/pizza_steak.zip\n",
        "\n",
        "# Unzip the downloaded file\n",
        "zip_ref = zipfile.ZipFile(\"pizza_steak.zip\")\n",
        "zip_ref.extractall()\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "KvEr_0u7aQno"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inspect the data (become one with it)\n",
        "\n",
        "A very crutial step at the beginning of any machine learning project is becoming one with the data.\n",
        "\n",
        "And for a computer vision project, this usually means visualizing many samples of your data."
      ],
      "metadata": {
        "id": "pwhR7VBPdR0r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls pizza_steak"
      ],
      "metadata": {
        "id": "apu_HaLqLIbY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls pizza_steak/train"
      ],
      "metadata": {
        "id": "YFuyGRJtLMFS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls pizza_steak/train/steak"
      ],
      "metadata": {
        "id": "EhUDtBrbLTdC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Walk through pizza_steak directory and list number of files\n",
        "for dirpath, dirnames, filenames in os.walk(\"pizza_steak\"):\n",
        "  print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")"
      ],
      "metadata": {
        "id": "xIeePq1uLXD1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Another way to find out how many images are in a file\n",
        "num_steak_images_train = len(os.listdir(\"pizza_steak/train/steak\"))\n",
        "num_steak_images_train"
      ],
      "metadata": {
        "id": "pHvM9MCXMdS0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To visualize our images, first let's get the class names programmatically"
      ],
      "metadata": {
        "id": "S1QXMdfwMv17"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the classnames programmatically\n",
        "import pathlib\n",
        "import numpy as np\n",
        "data_dir = pathlib.Path(\"pizza_steak/train\")\n",
        "class_names = np.array(sorted([item.name for item in data_dir.glob(\"*\")])) # Created a list of class_names from the subdirectories\n",
        "print(class_names)"
      ],
      "metadata": {
        "id": "my14YGFGM5WC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's visualize our images\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import random\n",
        "\n",
        "def view_random_image(target_dir, target_class):\n",
        "  # Setup the target directory (we'll view images from here)\n",
        "  target_folder = target_dir + target_class\n",
        "\n",
        "  # Get a random image path\n",
        "  random_image = random.sample(os.listdir(target_folder), 1)\n",
        "  print(random_image)\n",
        "\n",
        "  # Read in the image and plot it using matplotlib\n",
        "  img = mpimg.imread(target_folder + \"/\" + random_image[0])\n",
        "  plt.imshow(img)\n",
        "  plt.title(target_class)\n",
        "  plt.axis(\"off\")\n",
        "\n",
        "  print(f\"Image shape: {img.shape}\") # Show the shape of the image\n",
        "\n",
        "  return img"
      ],
      "metadata": {
        "id": "mFWj2t9ZNsxi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# View a random image from the training dataset\n",
        "img = view_random_image(target_dir=\"pizza_steak/train/\",\n",
        "                        target_class=\"steak\")"
      ],
      "metadata": {
        "id": "gtlos7CJPuLe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The images we've imported and plotted are actually giant arrays/tensors of different pixel values\n",
        "import tensorflow as tf\n",
        "tf.constant(img)"
      ],
      "metadata": {
        "id": "vW_0UcP2Q1u0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# View the image shape\n",
        "img.shape # Returns width, height, color channels"
      ],
      "metadata": {
        "id": "nnrJSCqTRQUt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:** As we've discussed before, many machine learning models, including neural networks prefer the values they work with to be between 0 and 1. Knowing this, one of the most common preprocessing steps for working with images is to **scale** (also referred to as **normalize**) their pixel values by dividing the image arrays by 255. (since 255 is the maximum pixel value)."
      ],
      "metadata": {
        "id": "X8jWPXlOSNPi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get all the pixel values between 0 & 1\n",
        "img / 255."
      ],
      "metadata": {
        "id": "B62-DAiwRaa_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## An end-to-end example\n",
        "\n",
        "Let's build a convolutional neural network to find patterns in our images, more specifically we need a way to:\n",
        "\n",
        "* Load our images.\n",
        "* Preprocess our images.\n",
        "* Build a CNN to find patterns in our images.\n",
        "* Compile our CNN.\n",
        "* Fit the CNN to out training data."
      ],
      "metadata": {
        "id": "8fovHUPgS3mG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Set the random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Preprocess data (get all of the pixel values between 0 & 1, scaling/normalization)\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Setup paths to our data directories\n",
        "train_dir = \"pizza_steak/train\"\n",
        "test_dir = \"pizza_steak/test\"\n",
        "\n",
        "# Import data from directories and turn it into batches\n",
        "train_data = train_datagen.flow_from_directory(directory=train_dir,\n",
        "                                               batch_size=32,\n",
        "                                               target_size=(224, 224),\n",
        "                                               class_mode=\"binary\",\n",
        "                                               seed=42)\n",
        "\n",
        "valid_data = valid_datagen.flow_from_directory(directory=test_dir,\n",
        "                                               batch_size=32,\n",
        "                                               target_size=(224, 224),\n",
        "                                               class_mode=\"binary\",\n",
        "                                               seed=42)\n",
        "\n",
        "# Build a CNN model (same as the Tiny VGG on the CNN explainer website)\n",
        "model_1 = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(filters=10,\n",
        "                           kernel_size=3,\n",
        "                           activation=\"relu\",\n",
        "                           input_shape=(224, 224, 3)),\n",
        "    tf.keras.layers.Conv2D(10, 3, activation=\"relu\"),\n",
        "    tf.keras.layers.MaxPool2D(pool_size=2,\n",
        "                              padding=\"valid\"),\n",
        "    tf.keras.layers.Conv2D(10, 3, activation=\"relu\"),\n",
        "    tf.keras.layers.Conv2D(10, 3, activation=\"relu\"),\n",
        "    tf.keras.layers.MaxPool2D(2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "# Compile our CNN\n",
        "model_1.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# Fit the model\n",
        "history_1 = model_1.fit(train_data,\n",
        "                        epochs=5,\n",
        "                        steps_per_epoch=len(train_data),\n",
        "                        validation_data=valid_data,\n",
        "                        validation_steps=len(valid_data))"
      ],
      "metadata": {
        "id": "5z10QOzvTcqI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a model summary\n",
        "model_1.summary()"
      ],
      "metadata": {
        "id": "gFnyusxTk8cc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using the same model as before\n",
        "\n",
        "Let's replicate the model we've built in a previous section to see if it works with our image data.\n",
        "\n",
        "The model we're building is from the TensorFlow Playground."
      ],
      "metadata": {
        "id": "sY9kmQWPlvac"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Create a model to replicate the TensorFlow Playground model\n",
        "model_2 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(224, 224, 3)),\n",
        "    tf.keras.layers.Dense(4, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(4, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(1, activation=\"sigmoid\"),\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model_2.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# Fit the model\n",
        "history_2 = model_2.fit(train_data,\n",
        "                        epochs=5,\n",
        "                        steps_per_epoch=len(train_data),\n",
        "                        validation_data=valid_data,\n",
        "                        validation_steps=len(valid_data))"
      ],
      "metadata": {
        "id": "kZ_0TJA5l9i3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a summary of model_2\n",
        "model_2.summary()"
      ],
      "metadata": {
        "id": "Ju17_VVfpk-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Despite having 20x more parameters than our CNN (model_1), model_2 performed terribly... Let's try to improve it!"
      ],
      "metadata": {
        "id": "-VeJ9m6rp15H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Create the mode (same as above but let's step it up a notch)\n",
        "model_3 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(224, 224, 3)),\n",
        "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(1, activation=\"sigmoid\"),\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model_3.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# Fit the model\n",
        "history_3 = model_3.fit(train_data,\n",
        "                        epochs=5,\n",
        "                        steps_per_epoch=len(train_data),\n",
        "                        validation_data=valid_data,\n",
        "                        validation_steps=len(valid_data))"
      ],
      "metadata": {
        "id": "AmOHqFOCqMgP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a summary of model_3\n",
        "model_3.summary()"
      ],
      "metadata": {
        "id": "FVXvhvoB-ehG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:** You can think of trainable parameters as **patterns a model can learn from data**. Intuitively, you might think more is better. And in lots of cases, it is. But in this case, the difference here is the two different styles of model we're using. Where a series of dense layers has a number of different learnable parameters connected to each other and hence a higher number of possible learnable patterns, **a convolutional neural network seeks to sort out and learn the most important patterns in an image**. So, even though there are less learnable parameters in our convolutional neural network, these are often more helpful in dechiphering between different **features** in an image."
      ],
      "metadata": {
        "id": "OnewsRxM-6IR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.summary()"
      ],
      "metadata": {
        "id": "c-TNexd6ARwy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Binary Classification: Let's break it down\n",
        "\n",
        "1. Become one with data (visualize, visualize, visualize).\n",
        "2. Preprocess the data (prepared it for our model, the main step here was scaling/normalizing & turning our data into batches).\n",
        "3. Create a model (start with a baseline).\n",
        "4. Fit the model.\n",
        "5. Evaluate the model.\n",
        "6. Adjust different patameters and improve the model (try to beat our baseline).\n",
        "7. Repeat untill satisfied (experiment, experiment, experiment)."
      ],
      "metadata": {
        "id": "YQGjh0KTAqCB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Become one with the data"
      ],
      "metadata": {
        "id": "N9iqQdXJBap0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the data\n",
        "plt.figure()\n",
        "plt.subplot(1, 2, 1)\n",
        "steak_img = view_random_image(\"pizza_steak/train/\", \"steak\")\n",
        "plt.subplot(1, 2, 2)\n",
        "pizza_img = view_random_image(\"pizza_steak/train/\", \"pizza\")"
      ],
      "metadata": {
        "id": "xsWlx0sEBhyp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Preprocess the data (prepare it for a model)"
      ],
      "metadata": {
        "id": "NMpxxlsdC54I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define directory dataset paths\n",
        "train_dir = \"pizza_steak/train/\"\n",
        "test_dir = \"pizza_steak/test/\""
      ],
      "metadata": {
        "id": "rbRrPQ0dDFnz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our next step is to turn our data into **batches**.\n",
        "\n",
        "A batch is a small subset of data. Rather than look at all ~10,000 images at one time, a model might only look at 32 at a time.\n",
        "\n",
        "It does this for a couple of reasons:\n",
        "\n",
        "1. 10,000 images (or more) might not fit into the memory of your processor (GPU).\n",
        "2. Trying to learn the pattern in 10,000 images in one hit could result in the model not being able to learn very well."
      ],
      "metadata": {
        "id": "veRb17uJDX4a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create training and test data generators and rescale the data\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "id": "ZWRzomKIEw6g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load in our image data from directories and turn them into batches\n",
        "train_data = train_datagen.flow_from_directory(directory=train_dir, # Target directory of images\n",
        "                                               target_size=(224, 224), # Target size of images (height, width)\n",
        "                                               class_mode=\"binary\", # Type of data we're working with\n",
        "                                               batch_size=32) # Size of minibatches to load data into\n",
        "test_data = test_datagen.flow_from_directory(directory=test_dir,\n",
        "                                             target_size=(224, 224),\n",
        "                                             class_mode=\"binary\",\n",
        "                                             batch_size=32)"
      ],
      "metadata": {
        "id": "DkIjjMTqFjvv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a sample of a training data batch\n",
        "images, labels = next(iter(train_data)) # Get the \"next\" batch of images/labels in train_data\n",
        "len(images), len(labels)"
      ],
      "metadata": {
        "id": "spMyrkRFH8_X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# How many batches are there?\n",
        "len(train_data)"
      ],
      "metadata": {
        "id": "B-nWOI3vJBQp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the first two images\n",
        "images[:2], images[0].shape"
      ],
      "metadata": {
        "id": "Cc5_nfVIJM-W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# View the first batch of labels\n",
        "labels"
      ],
      "metadata": {
        "id": "oHcC65l5JtvE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Create a CNN model (start with a baseline)\n",
        "\n",
        "A baseline is a relatively simple model or existing result that you setup when beginning a machine learning experiment and then as you keep experimenting, you try to beat the baseline.\n",
        "\n",
        "**Note:** In deep learning, there are almost an infinite amount of architectures you could create. So, one of the best ways to get started is to start with something simple and see if it works on your data and then introduce complexity as required (e.g. look at which current model is performing best in the field for your problem)."
      ],
      "metadata": {
        "id": "D1YhAHolKJDJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make the creation of our model a little easier\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPool2D, Activation\n",
        "from tensorflow.keras import Sequential"
      ],
      "metadata": {
        "id": "nqtCJDZoKzLI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the model (this will be our baseline, a 3 layer convolutional neural network)\n",
        "model_4 = Sequential([\n",
        "    Conv2D(filters=10, # filters is the number of sliding windows going across an input (higher = more complex model)\n",
        "           kernel_size=3, # The size of the sliding window going across an input\n",
        "           strides=1, # The size of the step the sliding window takes across an input\n",
        "           padding=\"valid\", # If \"same\", output shape is same as input shape, If \"valid\", output shape gets compressed\n",
        "           activation=\"relu\",\n",
        "           input_shape=(224, 224, 3)), # Input layer (specify input shape)\n",
        "    Conv2D(10, 3, activation=\"relu\"),\n",
        "    Conv2D(10, 3, activation=\"relu\"),\n",
        "    Flatten(),\n",
        "    Dense(1, activation=\"sigmoid\") # Output layer (working with binary classification...So, only 1 output neuron)\n",
        "])"
      ],
      "metadata": {
        "id": "VAHoq7PJLRNh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model_4.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "MuOfilyecbQC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a summary of our model\n",
        "model_4.summary()"
      ],
      "metadata": {
        "id": "tTv0wYqlc47e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Fit the model"
      ],
      "metadata": {
        "id": "3IiIC5cWc0r-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the lenghts of training and test data generators\n",
        "len(train_data), len(test_data)"
      ],
      "metadata": {
        "id": "eQRgrK3Ec3kR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "history_4 = model_4.fit(train_data, # This is a combination of labels and sample data\n",
        "                        epochs=5,\n",
        "                        steps_per_epoch=len(train_data),\n",
        "                        validation_data=test_data,\n",
        "                        validation_steps=len(test_data))"
      ],
      "metadata": {
        "id": "COK6PdInd2tS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Evaluating our model\n",
        "\n",
        "It looks like our model is learning something... Let's evaluate it!"
      ],
      "metadata": {
        "id": "fcg-EifJe4DS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's plot the training curves\n",
        "import pandas as pd\n",
        "pd.DataFrame(history_4.history).plot(figsize=(10, 7))"
      ],
      "metadata": {
        "id": "Rw6gxa9OfMl-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the validation and training curves seperately\n",
        "def plot_loss_curves(history):\n",
        "  \"\"\"\n",
        "  Returns seperate loss curves for training and validation metrics.\n",
        "  \"\"\"\n",
        "  loss = history.history[\"loss\"]\n",
        "  val_loss = history.history[\"val_loss\"]\n",
        "  accuracy = history.history[\"accuracy\"]\n",
        "  val_accuracy = history.history[\"val_accuracy\"]\n",
        "  epochs = range(len(history.history[\"loss\"])) # How many epochs did we run for?\n",
        "\n",
        "  # Plot loss\n",
        "  plt.plot(epochs, loss, label=\"training_loss\")\n",
        "  plt.plot(epochs, val_loss, label=\"val_loss\")\n",
        "  plt.title(\"loss\")\n",
        "  plt.xlabel(\"epochs\")\n",
        "  plt.legend()\n",
        "\n",
        "  # Plot accuracy\n",
        "  plt.figure()\n",
        "  plt.plot(epochs, accuracy, label=\"training_accuracy\")\n",
        "  plt.plot(epochs, val_accuracy, label=\"val_accuracy\")\n",
        "  plt.title(\"accuracy\")\n",
        "  plt.xlabel(\"epochs\")\n",
        "  plt.legend()"
      ],
      "metadata": {
        "id": "IIsCxwh1fedl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:** When a model's **validation loss starts to increase**, it's likely the model is **overfitting** the training dataset. This means, it's learning the patterns in the training dataset *too well* and thus the model's ability to generalize to unseen data will be diminished."
      ],
      "metadata": {
        "id": "NK8qHumFi-F_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out the loss and accuracy of model_4\n",
        "plot_loss_curves(history_4)"
      ],
      "metadata": {
        "id": "5iIMuRQyiQFE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Adjust the model parameters\n",
        "\n",
        "Fitting a machine learning model comes in 3 steps:\n",
        "\n",
        "0. Create a baseline.\n",
        "1. Beat the baseline by overfitting a larger model.\n",
        "2. Reduce overfitting.\n",
        "\n",
        "Ways to induce overfitting:\n",
        "\n",
        "* Increase the number of conv layers\n",
        "* Increase the number of conv filters\n",
        "* Add another dense layer to the output of our flattened layer.\n",
        "\n",
        "Reduce overfitting:\n",
        "\n",
        "* Add data augmentation.\n",
        "* Add regularization layers (such as MaxPool2D).\n",
        "* Add more data...\n",
        "\n",
        "> **Note:** Reducing overfitting is also known as **regularization**."
      ],
      "metadata": {
        "id": "Qz_asADhkuU3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the model (this is going to be our new baseline)\n",
        "model_5 = Sequential([\n",
        "    Conv2D(10, 3, activation=\"relu\", input_shape=(224, 224, 3)),\n",
        "    MaxPool2D(),\n",
        "    Conv2D(10, 3, activation=\"relu\"),\n",
        "    MaxPool2D(),\n",
        "    Conv2D(10, 3, activation=\"relu\"),\n",
        "    MaxPool2D(),\n",
        "    Flatten(),\n",
        "    Dense(1, activation=\"sigmoid\")\n",
        "])"
      ],
      "metadata": {
        "id": "kdfOo7fConM3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model_5.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "TUgc1os-qT3Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "history_5 = model_5.fit(train_data,\n",
        "                        epochs=5,\n",
        "                        steps_per_epoch=len(train_data),\n",
        "                        validation_data=test_data,\n",
        "                        validation_steps=len(test_data))"
      ],
      "metadata": {
        "id": "wFhZK0nuq2Qg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a summary of our model with max pooling\n",
        "model_5.summary()"
      ],
      "metadata": {
        "id": "nR0y4qwXsHM0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot loss curves\n",
        "plot_loss_curves(history_5)"
      ],
      "metadata": {
        "id": "jK88DvtgskSc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Opening our bag of tricks and finding data augmentation"
      ],
      "metadata": {
        "id": "NnrMsN78tqNf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create ImageDataGenerator training instance with data augmentation\n",
        "train_datagen_augmented = ImageDataGenerator(rescale=1./255,\n",
        "                                             rotation_range=0.2, # How much do you want to rotate an image?\n",
        "                                             shear_range=0.2, # How much do you want to shear an image?\n",
        "                                             zoom_range=0.2, # Zoom in randomly on an image\n",
        "                                             width_shift_range=0.2, # Move your images around on the x-axis\n",
        "                                             height_shift_range=0.2, # Move your images around on the y-axis\n",
        "                                             horizontal_flip=True) # Do you want to flip an image?\n",
        "\n",
        "# Create ImageDataGenerator without data augmentation\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Create ImageDataGenerator without data augmentation for the test dataset\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "id": "sxWeOMOmt4OS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question:** What is data augmentation?\n",
        "\n",
        "Data augmentation is the process of altering our training data, leading it to have more diversity and in turn allowing our models to learn more generalizable (hopefuly) patterns. Altering might mean adjusting the rotation of an image, flipping it, cropping it or something similar.\n",
        "\n",
        "Let's write some code to visualize data augmentation..."
      ],
      "metadata": {
        "id": "BtjiXDCevwsU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import data and augment it from training directory\n",
        "print(\"Augmented training data:\")\n",
        "train_data_augmented = train_datagen_augmented.flow_from_directory(train_dir,\n",
        "                                                                   target_size=(224, 224),\n",
        "                                                                   batch_size=32,\n",
        "                                                                   class_mode=\"binary\",\n",
        "                                                                   shuffle=False) # For demonstration purposes only\n",
        "\n",
        "# Create non-augmented train data batches\n",
        "print(\"Non-augmented training data:\")\n",
        "train_data = train_datagen.flow_from_directory(train_dir,\n",
        "                                               target_size=(224, 224),\n",
        "                                               batch_size=32,\n",
        "                                               class_mode=\"binary\",\n",
        "                                               shuffle=False)\n",
        "\n",
        "# Create non-augmented test data batches\n",
        "print(\"Non-augmented test data:\")\n",
        "test_data = test_datagen.flow_from_directory(test_dir,\n",
        "                                             target_size=(224, 224),\n",
        "                                             batch_size=32,\n",
        "                                             class_mode=\"binary\")"
      ],
      "metadata": {
        "id": "flMKk9JmwrYQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:** Data augmentation is usually only performed on the training data. Using `ImageDataGenerator` built-in data augmentation parameters our images are left as they are in the directories but are modified as they're loaded into the model.\n",
        "\n",
        "Finally... Let's visualize some augmented data!!!"
      ],
      "metadata": {
        "id": "PRgJ3xLw2nR0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get some sample augmented data batches\n",
        "images, labels = next(iter(train_data))\n",
        "augmented_images, augmented_labels = next(iter(train_data_augmented)) # Note: The labels aren't augmented... Only the data (images)"
      ],
      "metadata": {
        "id": "tOnukjo53n5G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show original image and augmented iamge\n",
        "import random\n",
        "random_number = random.randint(0, 32) # Our batch size is 32...\n",
        "print(f\"showing image number: {random_number}\")\n",
        "plt.imshow(images[random_number])\n",
        "plt.title(\"Original image\")\n",
        "plt.axis(False)\n",
        "plt.figure()\n",
        "plt.imshow(augmented_images[random_number])\n",
        "plt.title(\"Augmented image\")\n",
        "plt.axis(False)"
      ],
      "metadata": {
        "id": "4xI786Nn4c7_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we've seen what augmented training data looks like, let's build a model and see how it learns on augmented data."
      ],
      "metadata": {
        "id": "wemUBs697JGZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a model (same as model_5)\n",
        "model_6 = Sequential([\n",
        "    Conv2D(10, 3, activation=\"relu\"),\n",
        "    MaxPool2D(),\n",
        "    Conv2D(10, 3, activation=\"relu\"),\n",
        "    MaxPool2D(),\n",
        "    Conv2D(10, 3, activation=\"relu\"),\n",
        "    MaxPool2D(),\n",
        "    Flatten(),\n",
        "    Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model_6.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# Fit the model\n",
        "history_6 = model_6.fit(train_data_augmented, # Fitting model_6 on augmented training data\n",
        "                        epochs=5,\n",
        "                        steps_per_epoch=len(train_data_augmented),\n",
        "                        validation_data=test_data,\n",
        "                        validation_steps=len(test_data))"
      ],
      "metadata": {
        "id": "GA_XTfhe64Nj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check our models training curves\n",
        "plot_loss_curves(history_6)"
      ],
      "metadata": {
        "id": "pw0xVFUn8Lfe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's shuffle our augmented training data and train another model (the same as before) on it and see what happens."
      ],
      "metadata": {
        "id": "2Rd3jbG191b6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import data and augment it and shuffle from training directory\n",
        "training_data_augmented_shuffled = train_datagen_augmented.flow_from_directory(train_dir,\n",
        "                                                                               target_size=(224, 224),\n",
        "                                                                               batch_size=32,\n",
        "                                                                               class_mode=\"binary\",\n",
        "                                                                               shuffle=True) # Shuffle data this time"
      ],
      "metadata": {
        "id": "XES12tsd-JJX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the model (same as model_5 and model_6)\n",
        "model_7 = Sequential([\n",
        "    Conv2D(10, 3, activation=\"relu\"),\n",
        "    MaxPool2D(),\n",
        "    Conv2D(10, 3, activation=\"relu\"),\n",
        "    MaxPool2D(),\n",
        "    Conv2D(10, 3, activation=\"relu\"),\n",
        "    MaxPool2D(),\n",
        "    Flatten(),\n",
        "    Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model_7.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# Fit the model\n",
        "history_7 = model_7.fit(training_data_augmented_shuffled, # Now we're fitting on augmented and shuffled data\n",
        "                        epochs=5,\n",
        "                        steps_per_epoch=len(training_data_augmented_shuffled),\n",
        "                        validation_data=test_data,\n",
        "                        validation_steps=len(test_data))"
      ],
      "metadata": {
        "id": "ZQQfKlaC-xLM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot loss curves\n",
        "plot_loss_curves(history_7)"
      ],
      "metadata": {
        "id": "qgMhOLktAfDJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:** When shuffling training data, the mode gets exposed to all different kinds of data during training, this enabling it to learn features across a wide array of images (in our case, pizza & steak at the same time instead of just pizza then steak)"
      ],
      "metadata": {
        "id": "dlnRqkHEBGY-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Repeat untill satisfied\n",
        "\n",
        "Since we've already beaten our baseline, there are a few things we could try to continue to improve our model:\n",
        "\n",
        "* Increase the number of model layers (e.g. add more `Conv2D` / `MaxPool2D` layers).\n",
        "* Increse the number of filters in each convolutional layer (e.g. from 10 to 32 or even 64).\n",
        "* Train for longer (more epochs).\n",
        "* Find an ideal learning rate.\n",
        "* Get more data (give the model more opportunities to learn).\n",
        "* Use **tansfer learning** to leverage what another image model has learnt and adjust it for our own use case."
      ],
      "metadata": {
        "id": "tpv0ZLAYBqWc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Making a prediction with our trained model on our own custom data"
      ],
      "metadata": {
        "id": "zRFlSe9GNwYd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Classes we're working with\n",
        "print(class_names)"
      ],
      "metadata": {
        "id": "lFjoLXFCN2Vl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# View our example image\n",
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/refs/heads/main/images/03-steak.jpeg\n",
        "steak = mpimg.imread(\"03-steak.jpeg\")\n",
        "plt.imshow(steak)\n",
        "plt.axis(False)"
      ],
      "metadata": {
        "id": "RfQH8oZVPAd9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the shape of our image\n",
        "steak.shape"
      ],
      "metadata": {
        "id": "Y5Ii0a-JQdzA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:** When you train a neural network and you want to make a prediction with it on your own custom data (or new data) is preprocessed into the same format as the data your model was trained on."
      ],
      "metadata": {
        "id": "jbxkofinRUed"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "9spqBN-iZXG1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a function to import an image and resize it to able to used with our model\n",
        "def load_and_prep_image(filename, img_shape=224):\n",
        "  \"\"\"\n",
        "  Reads an image from filename, turns it into a tensor and reshapes it to (img_shape, img_shape, color_channels).\n",
        "  \"\"\"\n",
        "\n",
        "  # Read in the image\n",
        "  img = tf.io.read_file(filename)\n",
        "\n",
        "  # Decode the read file into a tensor\n",
        "  img = tf.image.decode_image(img)\n",
        "\n",
        "  # Resize the image\n",
        "  img = tf.image.resize(img, size=[img_shape, img_shape])\n",
        "\n",
        "  # Rescale the image (get all values between 0 and 1)\n",
        "  img = img / 255.\n",
        "\n",
        "  return img"
      ],
      "metadata": {
        "id": "k6JW53wBRzdm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load in and preprocess our custom image\n",
        "steak = load_and_prep_image(\"03-steak.jpeg\")\n",
        "steak"
      ],
      "metadata": {
        "id": "u_s_euk0Q8Pg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model_7.predict(tf.expand_dims(steak, axis=0))\n",
        "pred"
      ],
      "metadata": {
        "id": "oq14jyEgQuLL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looks like our custom image is being put through our model. However, it currently outputs a prediction probability, wouldn't it be nice if we could visualize the image as well as the model's prediction?"
      ],
      "metadata": {
        "id": "fXft8lDuUnlk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remind ourselves of our class names\n",
        "class_names"
      ],
      "metadata": {
        "id": "Td1QAW30US95"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we can index the predicted class by rounding the prediction probability and indexing it on the class names\n",
        "pred_class = class_names[int(tf.round(pred))]\n",
        "pred_class"
      ],
      "metadata": {
        "id": "f9xeQDWSVFg8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pred_and_plot(model, filename, class_names=class_names):\n",
        "  \"\"\"\n",
        "  Imports an image located at filename, makes a prediction with the model and plots the image with the predicted class as the title.\n",
        "  \"\"\"\n",
        "\n",
        "  # Import the target image and preprocess it\n",
        "  img = load_and_prep_image(filename)\n",
        "\n",
        "  # Make a prediction\n",
        "  pred = model.predict(tf.expand_dims(img, axis=0))\n",
        "\n",
        "  # Get the predicted class\n",
        "  pred_class = class_names[int(tf.round(pred))]\n",
        "\n",
        "  # Plot the image and predicted class\n",
        "  plt.imshow(img)\n",
        "  plt.title(f\"Prediction: {pred_class}\")\n",
        "  plt.axis(False)"
      ],
      "metadata": {
        "id": "pjVfPULxXRMf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test our model on a custom image\n",
        "pred_and_plot(model_7, \"03-steak.jpeg\")"
      ],
      "metadata": {
        "id": "JEfgakimYVYc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our model works! Let's try it on another image... This time pizza!"
      ],
      "metadata": {
        "id": "7axF-7gDZ2xq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download another test custom image and make a prediction on it\n",
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/refs/heads/main/images/03-pizza-dad.jpeg"
      ],
      "metadata": {
        "id": "fI5U-89JaBzh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test our model on a custom image\n",
        "pred_and_plot(model_7, \"03-pizza-dad.jpeg\")"
      ],
      "metadata": {
        "id": "plw6b8LlaNfQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mulitclass Image Classificaton\n",
        "\n",
        "We've just been through a bunch of the following steps with a binary classification problem (pizza vs. steak), now we're going to step things up a notch with 10 classes of food (multiclass classification).\n",
        "\n",
        "1. Become one with the data.\n",
        "2. Preprocess the data (get it ready for a model).\n",
        "3. Create a model (start with a baseline).\n",
        "4. Fit the model (overfit it to make sure it works).\n",
        "5. Evaluate the model.\n",
        "6. Adjust different hyperparameters and improve the model (try to beat baseline/reduce overfitting).\n",
        "7. Repeat until satisfied."
      ],
      "metadata": {
        "id": "dMPixakBbVz8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Import and become one with the data"
      ],
      "metadata": {
        "id": "sPNhMWDhch_t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_all_data.zip\n",
        "\n",
        "# Unzip our data\n",
        "zip_ref = zipfile.ZipFile(\"10_food_classes_all_data.zip\", \"r\")\n",
        "zip_ref.extractall()\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "36r9gbMbcwVh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Walk through 10 classes of food image data\n",
        "for dirpath, dirnames, filenames in os.walk(\"10_food_classes_all_data\"):\n",
        "  print(f\"There are {len(dirnames)} directories and len{len(filenames)} images in '{dirpath}'.\")"
      ],
      "metadata": {
        "id": "aE_V6t9mdcnv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup the train and test directories\n",
        "train_dir = \"10_food_classes_all_data/train/\"\n",
        "test_dir = \"10_food_classes_all_data/test/\""
      ],
      "metadata": {
        "id": "YwvIii9xekBM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's get the class names\n",
        "import pathlib\n",
        "import numpy as np\n",
        "data_dir = pathlib.Path(train_dir)\n",
        "class_names = np.array(sorted(item.name for item in data_dir.glob('*')))\n",
        "print(class_names)"
      ],
      "metadata": {
        "id": "l-aTnF07g6DI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize, visualize, visualize\n",
        "import random\n",
        "img = view_random_image(target_dir=train_dir,\n",
        "                        target_class=random.choice(class_names))"
      ],
      "metadata": {
        "id": "c92SjedJgqo3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Preprocess the data (prepare it for a model)"
      ],
      "metadata": {
        "id": "-20HqCPjilwk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Rescale\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Load data in from directories and turn it into batches\n",
        "train_data = train_datagen.flow_from_directory(train_dir,\n",
        "                                               target_size=(224, 224),\n",
        "                                               batch_size=32,\n",
        "                                               class_mode=\"categorical\")\n",
        "\n",
        "test_data = test_datagen.flow_from_directory(test_dir,\n",
        "                                              target_size=(224, 224),\n",
        "                                              batch_size=32,\n",
        "                                              class_mode=\"categorical\")"
      ],
      "metadata": {
        "id": "2ysEus_NivK8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Create a model (start with a baseline)\n",
        "\n",
        "We've been talking a lot about the CNN explainer website... How about we just take their model (also on 10 classes) and use it for our problem?"
      ],
      "metadata": {
        "id": "R9w8OuGWj6j-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Activation"
      ],
      "metadata": {
        "id": "g3IpU3Eek-3d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create our model (very similar to previous models but actually the same as CNN explainer website)\n",
        "model_8 = Sequential([\n",
        "    Conv2D(10, 3, input_shape=(224, 224, 3)),\n",
        "    Activation(activation=\"relu\"),\n",
        "    Conv2D(10, 3),\n",
        "    Activation(activation=\"relu\"),\n",
        "    MaxPool2D(),\n",
        "    Conv2D(10, 3),\n",
        "    Activation(activation=\"relu\"),\n",
        "    Conv2D(10, 3),\n",
        "    Activation(activation=\"relu\"),\n",
        "    MaxPool2D(),\n",
        "    Flatten(),\n",
        "    Dense(10),\n",
        "    Activation(activation=\"softmax\") # Changed to have 10 output neurons and use the softmax activation function\n",
        "])"
      ],
      "metadata": {
        "id": "8LMjgU54lRzz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model_8.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "psfb6aocnRzn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Fit the model"
      ],
      "metadata": {
        "id": "6LHbRds3nrmO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "history_8 = model_8.fit(train_data, # Now 10 different classes\n",
        "                        epochs=5,\n",
        "                        steps_per_epoch=len(train_data),\n",
        "                        validation_data=test_data,\n",
        "                        validation_steps=int(0.25 * len(test_data)))"
      ],
      "metadata": {
        "id": "rCTX5RHSpCii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Evaluate the model"
      ],
      "metadata": {
        "id": "ec88AsuUpavZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate on the test data\n",
        "model_8.evaluate(test_data)"
      ],
      "metadata": {
        "id": "-97hOPbhpktm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out the model's loss curves on the 10 classes\n",
        "plot_loss_curves(history_8)"
      ],
      "metadata": {
        "id": "cbn93kcipzxI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What do these loss curves tell us?\n",
        "\n",
        "Well... It seems our model is **overfitting** the training set quite badly... in other words, it's getting great results on the training data but fails to generalize well to unseen data and performs poorly on the test dataset."
      ],
      "metadata": {
        "id": "wKX3J7QjqPvR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Adjust the model hyperparameters (to beat the baseline/reduce overfitting)\n",
        "\n",
        "Due to its performance on the training data, it's clear our model is learning something...\n",
        "\n",
        "However, it's not generalizing well to unseen data (overfitting).\n",
        "\n",
        "So, let's try and fix overfitting by:\n",
        "\n",
        "* **Get more data** - having more data gives a model more opportunity to learn diverse patterns.\n",
        "* **Simplify the model** - if our current model is overfitting the data, it may be too complicated for a model, two ways to simply a model is to: reduce # of layers or reduce # of hidden units in the layers.\n",
        "* **Use data augmentation** - data augmentation manipulates the training data in such a way to add more diversity to it (without altering the original data).\n",
        "* **Use transfer learning** - transfer learning leverages the patterns, another model has learned on similar data to your own and allows you to use those patterns on your own dataset."
      ],
      "metadata": {
        "id": "Czeb1xlkrWDT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# How about we try and simplify the model first?\n",
        "# Let's try to remove 2 convolutional layers..."
      ],
      "metadata": {
        "id": "8kYx1LrnrfXs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the model\n",
        "model_9 = Sequential([\n",
        "    Conv2D(10, 3, input_shape=(224, 224, 3)),\n",
        "    Activation(activation=\"relu\"),\n",
        "    MaxPool2D(),\n",
        "    Conv2D(10, 3, input_shape=(224, 224, 3)),\n",
        "    Activation(activation=\"relu\"),\n",
        "    MaxPool2D(),\n",
        "    Flatten(),\n",
        "    Dense(10),\n",
        "    Activation(activation=\"softmax\")\n",
        "])"
      ],
      "metadata": {
        "id": "lFC0yNmizrSL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model_9.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "TCeR0Gsqzs1x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model with 2x Conv2D layers removed\n",
        "history_9 = model_9.fit(train_data,\n",
        "                        epochs=5,\n",
        "                        steps_per_epoch=len(train_data),\n",
        "                        validation_data=test_data,\n",
        "                        validation_steps=int(0.25 * len(test_data)))"
      ],
      "metadata": {
        "id": "GxUhSeUm0EQO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out the loss curves of model_9\n",
        "plot_loss_curves(history_9)"
      ],
      "metadata": {
        "id": "wlp8Je890u5T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looks like our \"simplifying the model\" experiment didn't work... The accuracy went down and overfitting continued...\n",
        "\n",
        "How about we try data augmentation?"
      ],
      "metadata": {
        "id": "_Y7OBQBg1LFi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Trying to reduce overfitting with data augmentation\n",
        "\n",
        "Let's try and improve our model's results by using augmented training data...\n",
        "\n",
        "Ideally, we want to:\n",
        "\n",
        "* Reduce overfitting (get the train and validation loss curves closer).\n",
        "* Improve validation accuracy."
      ],
      "metadata": {
        "id": "7FzbiHzL1eKv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an augmented data generator instance\n",
        "train_datagen_augmented = ImageDataGenerator(rescale=1./255,\n",
        "                                             rotation_range=0.2,\n",
        "                                             width_shift_range=0.2,\n",
        "                                             height_shift_range=0.2,\n",
        "                                             zoom_range=0.2,\n",
        "                                             horizontal_flip=True)\n",
        "\n",
        "train_data_augmented = train_datagen_augmented.flow_from_directory(train_dir,\n",
        "                                                                   target_size=(224, 224),\n",
        "                                                                   batch_size=32,\n",
        "                                                                   class_mode=\"categorical\")"
      ],
      "metadata": {
        "id": "m8y53c8t1tcL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's create another model but this time we'll fit it on the augmented training data of 10 classes\n",
        "model_10 = tf.keras.models.clone_model(model_8)"
      ],
      "metadata": {
        "id": "BwUA5PSO3YcO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the same model (using the same setup as previous models)\n",
        "model_10.compile(loss=\"categorical_crossentropy\",\n",
        "                 optimizer=tf.keras.optimizers.Adam(),\n",
        "                 metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "UUC9qphg33tO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "history_10 = model_10.fit(train_data_augmented,\n",
        "                          epochs=5,\n",
        "                          steps_per_epoch=len(train_data_augmented),\n",
        "                          validation_data=test_data,\n",
        "                          validation_steps=int(0.25 * len(test_data)))"
      ],
      "metadata": {
        "id": "qhNtDYaJ4hPz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_8.evaluate(test_data)"
      ],
      "metadata": {
        "id": "ogu1e3Gh5bum"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_10.evaluate(test_data)"
      ],
      "metadata": {
        "id": "opVwaVmU5frM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out our model trained on augmented data's loss curves\n",
        "plot_loss_curves(history_10)"
      ],
      "metadata": {
        "id": "qqIxLdBT5kNZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Woah! That looks much better, the loss curves are much closer to each other than the baseline model and they look like they're heading in the right direction (certainly not the wrong direction). So, if we were to train for longer, we might see further improvements."
      ],
      "metadata": {
        "id": "bVdV5agV6BSt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Repeat until satisfied\n",
        "\n",
        "We could keep going here... Continually trying to bring our loss curves closer together and trying to improve the validation/test accuracy.\n",
        "\n",
        "How?\n",
        "\n",
        "By running lots of experiments, namely:\n",
        "\n",
        "- Restructuring our model's architecture (increasing layers/hidden units).\n",
        "- Adjust the learning rate.\n",
        "- Try different methods of data augmentation (adjust the hyperparameters in our ImageDataGenerator instance).\n",
        "- Training for longer (e.g. 10 epochs instead of 5 epochs).\n",
        "- Try **transfer learning**."
      ],
      "metadata": {
        "id": "C2R2Ja9-6ji6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Making a prediction with our trained model\n",
        "\n",
        "Let's use our trained model to make some predictions on our own custom images!"
      ],
      "metadata": {
        "id": "fcIA_5V28PSY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remind ourselves of the classes our model is trained on\n",
        "class_names"
      ],
      "metadata": {
        "id": "c6ZUoGjD8qA_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download some custom images\n",
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/03-pizza-dad.jpeg\n",
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/03-hamburger.jpeg\n",
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/03-sushi.jpeg\n",
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/03-steak.jpeg"
      ],
      "metadata": {
        "id": "vhhcRU989I3s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reconfig pred_and_plot function to work with multiclass images\n",
        "def pred_and_plot(model, filename, class_names=class_names):\n",
        "  \"\"\"\n",
        "  Imports an image located at filename, makes a prediction with the model and plots the image with the predicted class as the title.\n",
        "  \"\"\"\n",
        "\n",
        "  # Import the target image and preprocess it\n",
        "  img = load_and_prep_image(filename)\n",
        "\n",
        "  # Make a prediction\n",
        "  pred = model.predict(tf.expand_dims(img, axis=0))\n",
        "\n",
        "  # Add in logic for multiclass & get pred_class name\n",
        "  if len(pred[0]) > 1:\n",
        "    pred_class = class_names[tf.argmax(pred[0])]\n",
        "  else:\n",
        "    pred_class = class_names[int(tf.round(pred))]\n",
        "\n",
        "  # Plot the image and predicted class\n",
        "  plt.imshow(img)\n",
        "  plt.title(f\"Prediction: {pred_class}\")\n",
        "  plt.axis(False)"
      ],
      "metadata": {
        "id": "WSuFWQiM-Ze_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a prediction using model_10\n",
        "pred_and_plot(model=model_10,\n",
        "              filename=\"03-pizza-dad.jpeg\",\n",
        "              class_names=class_names)"
      ],
      "metadata": {
        "id": "z2zgqi0A9tsb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a prediction using model_10\n",
        "pred_and_plot(model=model_10,\n",
        "              filename=\"03-hamburger.jpeg\",\n",
        "              class_names=class_names)"
      ],
      "metadata": {
        "id": "jIG20EYp_5_B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a prediction using model_10\n",
        "pred_and_plot(model=model_10,\n",
        "              filename=\"03-sushi.jpeg\",\n",
        "              class_names=class_names)"
      ],
      "metadata": {
        "id": "lQ-4-ElxAKIW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a prediction using model_10\n",
        "pred_and_plot(model=model_10,\n",
        "              filename=\"03-steak.jpeg\",\n",
        "              class_names=class_names)"
      ],
      "metadata": {
        "id": "78qqPapQAKXk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looks like our model didn't perform well on our custom images... Because it only achieved ~39& accuracy on the test data. So, we can expect it to function quite poorly on other unseen data."
      ],
      "metadata": {
        "id": "A01V2_M3I6uq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving and loading our model"
      ],
      "metadata": {
        "id": "WvoznWvAJWzM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save a model\n",
        "model_10.save(\"saved_trained_model_10.keras\")"
      ],
      "metadata": {
        "id": "AKWMwy83JlAU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load in a trained model and evaluate it\n",
        "loaded_model_10 = tf.keras.models.load_model(\"saved_trained_model_10.keras\")"
      ],
      "metadata": {
        "id": "zvpIKKNMKLIm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare our loaded model to our existing model\n",
        "loaded_model_10.evaluate(test_data)\n",
        "model_10.evaluate(test_data)"
      ],
      "metadata": {
        "id": "yOcLJtn9KlwQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}